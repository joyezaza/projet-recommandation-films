# üåê Syst√®me de Recommandation de Films - Projet Final

**Auteur : Joye Badou**  
**Produit Final Fonctionnel**

---

##  Sommaire

- [Introduction](#introduction)
- [I. Phase de Collecte des Donn√©es](#i-phase-de-collecte-des-donn√©es)
- a. Chargement des fichiers (`ratings.csv`, `movies.csv`, etc.)
- b. V√©rification de la structure des fichiers
  - Description des donn√©es `movie.csv`
  - Description des donn√©es `rating.csv`
- c. Centralisation des donn√©es dans un syst√®me structur√© (HDFS)
- [II. Phase de Fiabilisation et Normalisation](#ii-phase-de-fiabilisation-et-normalisation)
- Nettoyage `rating.csv`
- Nettoyage `movie.csv`
- Fusion des donn√©es
- [III. Phase d‚ÄôAnalyse Exploratoire](#iii-phase-danalyse-exploratoire)
1. Analyse des Films  
2. Analyse des Notes  
3. Analyse des Genres  
4. Analyse des Utilisateurs
- [IV & V. Phase de Mod√©lisation et d‚Äô√âvaluation](#iv--v-phase-de-mod√©lisation-et-d√©valuation)
- a. Pr√©paration des donn√©es pour la matrice utilisateur-item
- b. Impl√©mentation de KNN pour le filtrage collaboratif
  - Mod√®le User-User : Cr√©ation
  - Mod√®le User-User : √âvaluation
  - Mod√®le Item-Item : Cr√©ation
  - Mod√®le Item-Item : √âvaluation
- c. D√©veloppement d‚Äôun mod√®le bas√© sur le contenu (genres)
  - Mod√®le bas√© sur le contenu : Cr√©ation
  - Mod√®le bas√© sur le contenu : √âvaluation
- d. Cr√©ation d‚Äôun mod√®le hybride combinant les deux approches
  - Mod√®le Hybrid Content-User : Cr√©ation
  - Mod√®le Hybrid Content-User : √âvaluation
  - Mod√®le Hybrid Content-Item : Cr√©ation
  - Mod√®le Hybrid Content-Item : √âvaluation
- e. Optimisation des hyperparam√®tres pour am√©liorer les performances
  - Mod√®le Item-Item KNN : Optimisation
  - Mod√®le Hybrid Content-Item KNN : Optimisation
- [VI. Produit Final Fonctionnel et D√©ploiement](#vi-produit-final-fonctionnel-et-d√©ploiement)
1. Script Python interactif permettant √† un utilisateur d‚Äôentrer son userId et de recevoir des recommandations
2. API RESTful
3. Guide d'utilisation du syst√®me de recommandation de films
4. Lien GitHub
- [Conclusion](#conclusion)

---

## Introduction

Mon projet portera sur l‚Äôanalyse et la mod√©lisation des donn√©es du jeu de donn√©es MovieLens, une collection comprenant plus de 100000 notations et 943 utilisateurs et environ 1682 films. Malgr√© l'ambition initiale de travailler sur le dataset MovieLens contenant 33 millions de notations, nous avons opt√© pour le dataset de 100‚ÄØ000 notations (disponible sur Kaggle √† l'adresse ce lien) pour plusieurs raisons.

Tout d'abord, le dataset complet de 33 millions de notations n√©cessite des ressources mat√©rielles (m√©moire vive, temps de calcul) consid√©rablement sup√©rieures, ce qui complique la manipulation et le traitement des donn√©es, surtout dans un environnement de d√©veloppement standard. Ensuite, le dataset 100‚ÄØk offre un compromis optimal, il est suffisamment riche pour capturer des tendances et g√©n√©rer des recommandations fiables, tout en restant maniable et permettant une it√©ration rapide des mod√®les et analyses.

Par ailleurs, bien que l'√©tude des tags ait √©t√© envisag√©e, elle a √©t√© finalement √©cart√©e pour cette version du projet en raison de la complexit√© suppl√©mentaire qu'elle imposerait au processus de mod√©lisation. En se concentrant sur les fichiers movies et ratings, nous avons pu b√¢tir un syst√®me de recommandation solide et efficace, qui r√©pond aux objectifs du projet sans surcharge de complexit√© ni de contraintes mat√©rielles.

---

## I. Phase de Collecte des Donn√©es

### a. Chargement des fichiers (`ratings.csv`, `movies.csv`, etc.)

Les fichiers sources ont √©t√© t√©l√©charg√©s √† partir de Kaggle √† l'adresse *ce lien*. C‚Äôest un fichier `.zip` qui contient plusieurs donn√©es. Nous nous int√©resserons uniquement √† `u.data` (renomm√© et converti en `rating.csv`) et √† `u.item` (renomm√© et converti en `movie.csv`).

Voici les chemins des fichiers utilis√©s :
- `C:\Users\joyeb\Downloads\archive (4).zip`
- `C:\projet_work\Data-source\movie.csv`
- `C:\projet_work\Data-source\rating.csv`

####  Code : `convert_to_csv.py`

```python
import pandas as pd

# Chemins des fichiers d'entr√©e et de sortie
u_data_path = r"C:\projet_work\Data-source\u.data"
u_item_path = r"C:\projet_work\Data-source\u.item"
ratings_output_path = r"C:\projet_work\Data-source\rating.csv"
movies_output_path = r"C:\projet_work\Data-source\movie.csv"

# Conversion de u.data en rating.csv
def convert_u_data_to_csv(input_path, output_path):
    try:
        # Chargement des donn√©es avec les colonnes appropri√©es
        column_names = ['user_id', 'movie_id', 'rating', 'timestamp']
        u_data = pd.read_csv(input_path, sep='\t', names=column_names, header=None)
        u_data.to_csv(output_path, index=False)
        print(f" Conversion de {input_path} en {output_path} r√©ussie.")
    except Exception as e:
        print(f"‚ùå Erreur lors de la conversion de {input_path} : {e}")

# Conversion de u.item en movie.csv
def convert_u_item_to_csv(input_path, output_path):
    try:
        column_names = [
            'movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL',
            'unknown', 'Action', 'Adventure', 'Animation', "Children's", 'Comedy', 'Crime',
            'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',
            'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'
        ]
        u_item = pd.read_csv(input_path, sep='|', names=column_names, encoding='latin-1', header=None)
        u_item.to_csv(output_path, index=False)
        print(f" Conversion de {input_path} en {output_path} r√©ussie.")
    except Exception as e:
        print(f"‚ùå Erreur lors de la conversion de {input_path} : {e}")

# Ex√©cution des conversions
convert_u_data_to_csv(u_data_path, ratings_output_path)
convert_u_item_to_csv(u_item_path, movies_output_path)

‚ñ∂Ô∏è Ex√©cution dans le terminal

PS C:\Users\joyeb> cd C:\projet_work\Script
PS C:\projet_work\Script> python convert_to_csv.py
 Conversion de C:\projet_work\Data-source\u.data en C:\projet_work\Data-source\rating.csv r√©ussie.
 Conversion de C:\projet_work\Data-source\u.item en C:\projet_work\Data-source\movie.csv r√©ussie.

### b. V√©rification de la structure des fichiers

####  Description des donn√©es `movie.csv`

```python
import pandas as pd

# D√©finition du chemin du fichier
movies_path = r"C:\pyprojet\processed_data\movie.csv"

# Chargement des donn√©es
try:
    movies_df = pd.read_csv(movies_path)
    print(" Fichier charg√© avec succ√®s.")
except FileNotFoundError:
    print(f"‚ùå Erreur : Fichier introuvable √† l'emplacement {movies_path}.")
    exit()
except Exception as e:
    print(f"‚ùå Une erreur est survenue lors du chargement : {e}")
    exit()

# Analyse des donn√©es
num_rows, num_cols = movies_df.shape
column_info = movies_df.dtypes
num_unique_titles = movies_df['movie_title'].nunique()
genre_columns = [
    'unknown', 'Action', 'Adventure', 'Animation', "Children's", 'Comedy', 'Crime',
    'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',
    'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'
]
num_movies_per_genre = movies_df[genre_columns].sum()
num_missing_release_dates = movies_df['release_date'].isnull().sum()
num_missing_video_dates = movies_df['video_release_date'].isnull().sum()
first_three_rows = movies_df.head(3)

# R√©sultats
print("\n Analyse du fichier movie.csv ")
print(f"Nombre de lignes : {num_rows}")
print(f"Nombre de colonnes : {num_cols}\n")
print("Nom et type des colonnes :")
print(column_info, "\n")
print(f"Nombre de titres uniques : {num_unique_titles}\n")
print(" Nombre de films par genre (y compris 'unknown') :")
print(num_movies_per_genre, "\n")
print(f"Nombre de dates de sortie manquantes : {num_missing_release_dates}")
print(f"Nombre de dates de sortie vid√©o manquantes : {num_missing_video_dates}\n")
print("Aper√ßu des trois premi√®res lignes :")
print(first_three_rows)

#### ‚ñ∂Ô∏è Ex√©cution dans le terminal

```bash
PS C:\projet_work\Script> python analyse_movie.py

‚ñ∂Ô∏è R√©sultats utiles du script analyse_movie.py

Nombre de lignes : 1682
Nombre de colonnes : 24

Types des colonnes :
- movie_id : int64
- movie_title : object
- release_date : object
- video_release_date : float64
...

Nombre de titres uniques : 1664

Nombre de films par genre :
Drama       : 725
Comedy      : 505
Action      : 251
Thriller    : 251
Romance     : 247
...

Nombre de dates de sortie manquantes : 1
Nombre de dates de sortie vid√©o manquantes : 1682

Aper√ßu des trois premi√®res lignes :
   movie_id        movie_title release_date  ...  Sci-Fi  Thriller  War  Western
0         1   Toy Story (1995)  01-Jan-1995  ...       0         0    0        0
1         2   GoldenEye (1995)  01-Jan-1995  ...       0         1    0        0
2         3  Four Rooms (1995)  01-Jan-1995  ...       0         1    0        0
[3 rows x 24 columns]

 Analyse des r√©sultats

‚Ä¢	Nombre de lignes : 1682
‚Ä¢	Nombre de colonnes : 24
‚Ä¢	Types de colonnes :
o	movie_id est un entier (int64)
o	movie_title et release_date sont des objets (object), ce qui signifie qu'ils sont probablement des cha√Ænes de caract√®res.
o	video_release_date est un flottant (float64)
o	Les colonnes de genre (unknown, Action, etc.)
‚Ä¢	Nombre de titres uniques : 1664
‚Ä¢	Distribution des genres :
o	Le genre le plus courant est le Drama (725 films), suivi de Comedy (505 films).
o	Action et Thriller ont √©galement une fr√©quence √©lev√©e (251 films chacun).
o	Les genres les moins courants sont Fantasy (22 films) et Western (27 films).
o	Il y a 2 films class√©s comme unknown.
‚Ä¢	Dates de sortie manquantes : 1
‚Ä¢	Dates de sortie vid√©o manquantes : 1682
‚Ä¢	Exemple de donn√©es :
o	Les trois premi√®res lignes montrent des exemples de films avec leurs informations de base et leurs genres.
o	La colonne video_release_date contient des valeurs NaN
o	Les colonnes de genre contiennent des valeurs binaires (0 ou 1)

Description des donn√©es rating.csv
####  Code : `analyse_rating.py`
#### Code : `analyse_rating.py`

```python
import pandas as pd

# Chargement du fichier rating.csv
ratings = pd.read_csv(r'C:\projet_work\Data-source\rating.csv')

# Aper√ßu des premi√®res lignes
print("Aper√ßu des premi√®res lignes :")
print(ratings.head(), "\n")

# Nombre total de lignes
nb_lignes = ratings.shape[0]
print(f"Nombre total de lignes : {nb_lignes}")

# Nombre de colonnes
nb_colonnes = ratings.shape[1]
print(f"Nombre de colonnes : {nb_colonnes}\n")

# D√©tection des notes aberrantes (outliers) dans 'rating'
Q1 = ratings['rating'].quantile(0.25)
Q3 = ratings['rating'].quantile(0.75)
IQR = Q3 - Q1
borne_inf = Q1 - 1.5 * IQR
borne_sup = Q3 + 1.5 * IQR
outliers = ratings[(ratings['rating'] < borne_inf) | (ratings['rating'] > borne_sup)]
nb_outliers = outliers.shape[0]
print(f"Nombre de notes aberrantes d√©tect√©es (outliers) : {nb_outliers}\n")

# Valeurs manquantes par colonne
valeurs_manquantes = ratings.isna().sum()
print("Valeurs manquantes par colonne :")
print(valeurs_manquantes, "\n")

# Nombre total de valeurs manquantes
nb_total_manquantes = valeurs_manquantes.sum()
print(f"Nombre total de valeurs manquantes : {nb_total_manquantes}\n")

# Nombre d'entr√©es utilisateur (user_id) en double
nb_user_duplicates = ratings.duplicated(subset='user_id').sum()
print(f"Nombre d'entr√©es utilisateur (user_id) en double : {nb_user_duplicates}")

# Nombre d'entr√©es film (movie_id) en double
nb_movie_duplicates = ratings.duplicated(subset='movie_id').sum()
print(f"Nombre d'entr√©es film (movie_id) en double : {nb_movie_duplicates}")

# Nombre de lignes enti√®rement dupliqu√©es
nb_total_duplicates = ratings.duplicated().sum()
print(f"Nombre de lignes enti√®rement dupliqu√©es : {nb_total_duplicates}\n")

# Aper√ßu des entr√©es utilisateur en double
print("Aper√ßu des entr√©es utilisateur en double :")
print(ratings[ratings.duplicated(subset='user_id', keep=False)].sort_values('user_id').head(), "\n")

# Aper√ßu des entr√©es film en double
print("Aper√ßu des entr√©es film en double :")
print(ratings[ratings.duplicated(subset='movie_id', keep=False)].sort_values('movie_id').head())
```markdown
#### ‚ñ∂Ô∏è Ex√©cution dans le terminal

```bash
PS C:\projet_work\Script> python analyse_rating.py
‚ñ∂Ô∏è R√©sultats utiles du script analyse_rating.py
Nombre total de lignes : 100000
Nombre de colonnes : 4
Nombre de notes aberrantes d√©tect√©es (outliers) : 6110

Valeurs manquantes par colonne :
user_id      0
movie_id     0
rating       0
timestamp    0

Nombre total de valeurs manquantes : 0
Nombre d'entr√©es utilisateur (user_id) en double : 99057
Nombre d'entr√©es film (movie_id) en double : 98318
Nombre de lignes enti√®rement dupliqu√©es : 0

Aper√ßu des entr√©es utilisateur en double :
       user_id  movie_id  rating  timestamp
92049        1        28       4  875072173
62820        1       203       4  878542231
34165        1        75       4  878543238
972          1       117       3  874965739
15764        1       196       5  874965677

Aper√ßu des entr√©es film en double :
       user_id  movie_id  rating  timestamp
48383      749         1       4  881602577
74132      764         1       4  876244181
21683      256         1       5  882150980
89335      922         1       5  891448551
86548      881         1       4  876535796

 Analyses des r√©sultats

‚Ä¢ Aper√ßu des premi√®res lignes :
o Les premi√®res lignes montrent la structure du fichier rating.csv, avec les colonnes user_id, movie_id, rating, et timestamp.o Les notes (rating) varient de 1 √† 5, ce qui est attendu.
‚Ä¢ Nombre total de lignes : 100000
‚Ä¢ Nombre de colonnes : 4
‚Ä¢ Nombre de notes aberrantes d√©tect√©es (outliers) : 6110
o Il y a des notes qui s'√©cartent significativement de la distribution g√©n√©rale.
‚Ä¢ Valeurs manquantes par colonne :
o Aucune valeur manquante n'est d√©tect√©e dans aucune colonne.
‚Ä¢ Nombre total de valeurs manquantes : 0
‚Ä¢ Nombre d'entr√©es utilisateur (user_id) en double : 99057
o Cela indique que la plupart des utilisateurs ont donn√© plusieurs notes.
‚Ä¢ Nombre d'entr√©es film (movie_id) en double : 98318
o De m√™me, la plupart des films ont re√ßu plusieurs notes.
‚Ä¢ Nombre de lignes enti√®rement dupliqu√©es : 0
o Il n'y a pas de lignes enti√®rement dupliqu√©es, ce qui est positif.
‚Ä¢ Aper√ßu des entr√©es utilisateur en double :
o Les exemples montrent que l'utilisateur 1 a donn√© plusieurs notes √† diff√©rents films.
‚Ä¢ Aper√ßu des entr√©es film en double :
o Les exemples montrent que le film 1 a re√ßu plusieurs notes de diff√©rents utilisateurs.

- c. Centralisation des donn√©es dans un syst√®me structur√© (HDFS)
#### ‚ñ∂Ô∏è Centralisation des donn√©es dans un syst√®me structur√© (HDFS)

Je vais charger les donn√©es fusionn√©es dans HDFS, comme je l‚Äôavais annonc√©, mais je vais faire tout le reste du travail ‚Äî c‚Äôest-√†-dire l‚ÄôEDA, la mod√©lisation, etc. ‚Äî en local.

##### ‚ñ∂Ô∏è Ouverture du syst√®me HDFS

```bash
PS C:\Users\joyeb> cd C:\hadoop-3.3.5\sbin
PS C:\hadoop-3.3.5\sbin> ./start-dfs.cmd
PS C:\hadoop-3.3.5\sbin> ./start-yarn.cmd
starting yarn daemons

‚ñ∂Ô∏è V√©rification des diff√©rents n≈ìuds
PS C:\hadoop-3.3.5\sbin> jps
45888 NodeManager
44452 NameNode
45240 ResourceManager
32812 Jps
42028 DataNode
‚ñ∂Ô∏è Chargement des donn√©es dans HDFS
PS C:\hadoop-3.3.5\sbin> hdfs dfs -put C:\projet_work\Data-source\merged_final_data.csv /user/joyeb/merged_final_data.csv
‚ñ∂Ô∏è Taille et nombre de blocs
PS C:\hadoop-3.3.5\sbin> hdfs dfs -du -h /user/joyeb/merged_final_data.csv
7.9 M  7.9 M  /user/joyeb/merged_final_data.csv
‚ñ∂Ô∏è V√©rification de l'int√©grit√© avec FSCK
PS C:\hadoop-3.3.5\sbin> hdfs fsck /user/joyeb/merged_final_data.csv -files -blocks -locations
Status: HEALTHY
Total size: 8247603 B (‚âà7.9 MB)
Total blocks: 1 (avg. block size 8247603 B)
Replicated blocks: 1 (replication factor: 1)
Missing/Corrupt blocks: 0
 Bref commentaire :
Le rapport montre que le fichier /user/joyeb/merged_final_data.csv occupe environ 7,9 Mo dans HDFS.
Il a √©t√© stock√© dans un unique bloc, avec une r√©plication minimale (1).
‚úÖ Aucun probl√®me d√©tect√© ‚Äî le fichier est sain et bien localis√©.

## II. Phase de Fiabilisation et Normalisation
Dans cette phase nous allons en gros nettoyer les donn√©es.

###  Nettoyage de `rating.csv`

**Op√©rations r√©alis√©es :**

- **Supprimer les lignes enti√®rement doubl√©es :**  
  - Identifier et √©liminer les enregistrements identiques dans le jeu de donn√©es.  
  - ‚ö†Ô∏è Pourquoi ? Les doublons faussent les analyses et les r√©sultats du mod√®le.

- **Supprimer la colonne `timestamp` :**  
  - Retirer cette colonne car elle n‚Äôest pas utilis√©e dans l‚Äôanalyse.

- **Supprimer les films ayant moins de 3 notes :**  
  - Ces films fournissent peu d‚Äôinformation pour une recommandation fiable.

- **Supprimer les utilisateurs ayant not√© moins de 3 films :**  
  - Ces utilisateurs n‚Äôont pas un profil suffisant pour une recommandation personnalis√©e.

- **Supprimer les utilisateurs ayant not√© un nombre anormalement √©lev√© de films (au-dessus du 99e percentile) :**  
  - ‚ö†Ô∏è Pourquoi ? Ce sont potentiellement des comportements extr√™mes ou des anomalies.

- **Supprimer les utilisateurs avec une variance des notes < 0.1 :**  
  - Ces utilisateurs notent tous les films pareil ‚Üí aucune personnalisation utile.

- **Supprimer les films ayant uniquement des notes extr√™mes (1.0 ou 5.0) :**  
  - Ce sont souvent des cas biais√©s ou non repr√©sentatifs.

- **Cr√©er une colonne `rating_normalized` (Min-Max normalization) :**  
  - Mise √† l‚Äô√©chelle des notes entre 0 et 1 pour certains mod√®les.

‚û°Ô∏è Ces √©tapes ont √©t√© appliqu√©es pour garantir la **qualit√©**, la **coh√©rence**, et la **fiabilit√©** des donn√©es avant de passer √† l‚Äôanalyse et √† la mod√©lisation.

```markdown
### Code : `clean_ratings.py`
```python
import pandas as pd
import numpy as np

# Chargement du fichier rating.csv
ratings = pd.read_csv(r'C:\projet_work\Data-source\rating.csv')

# Suppression des lignes enti√®rement doubl√©es
nb_doublons = ratings.duplicated().sum()
ratings_clean = ratings.drop_duplicates()
print(f"Nombre de lignes enti√®rement doubl√©es supprim√©es : {nb_doublons}")

# Suppression de la colonne timestamp
ratings_clean = ratings_clean.drop(columns=['timestamp'])

# Suppression des films ayant moins de 3 notes
film_counts = ratings_clean['movie_id'].value_counts()
films_a_supprimer = film_counts[film_counts < 3].index
ratings_clean = ratings_clean[~ratings_clean['movie_id'].isin(films_a_supprimer)]

# Suppression des utilisateurs ayant not√© moins de 3 films
user_counts = ratings_clean['user_id'].value_counts()
users_a_supprimer = user_counts[user_counts < 3].index
ratings_clean = ratings_clean[~ratings_clean['user_id'].isin(users_a_supprimer)]

# Suppression des utilisateurs ayant un nombre excessif de notations (99e percentile)
user_counts_updated = ratings_clean['user_id'].value_counts()
seuil_99 = np.percentile(user_counts_updated, 99)
users_excessifs = user_counts_updated[user_counts_updated > seuil_99].index
ratings_clean = ratings_clean[~ratings_clean['user_id'].isin(users_excessifs)]

# Suppression des utilisateurs avec variance des notes < 0.1
user_variances = ratings_clean.groupby('user_id')['rating'].var()
users_variance_faible = user_variances[user_variances < 0.1].index
ratings_clean = ratings_clean[~ratings_clean['user_id'].isin(users_variance_faible)]

# Suppression des films avec uniquement des notes √† 1.0 ou 5.0
film_notes_unique = ratings_clean.groupby('movie_id')['rating'].nunique()
films_uniques = film_notes_unique[film_notes_unique == 1].index

films_extremes = []
for film_id in films_uniques:
    note = ratings_clean[ratings_clean['movie_id'] == film_id]['rating'].iloc[0]
    if note in [1.0, 5.0]:
        films_extremes.append(film_id)

ratings_clean = ratings_clean[~ratings_clean['movie_id'].isin(films_extremes)]

# Normalisation Min-Max
min_rating = ratings_clean['rating'].min()
max_rating = ratings_clean['rating'].max()
ratings_clean['rating_normalized'] = (ratings_clean['rating'] - min_rating) / (max_rating - min_rating)

# Sauvegarde
ratings_clean.to_csv(r'C:\projet_work\Data-source\clean_rating.csv', index=False)

#### ‚ñ∂Ô∏è Ex√©cution du script `clean_ratings.py`

```bash
PS C:\projet_work\Script> python clean_ratings.py
Nombre de lignes enti√®rement doubl√©es supprim√©es : 0
Nombre de films supprim√©s (moins de 3 notations) : 209
Nombre d'utilisateurs supprim√©s (moins de 3 notes) : 0
Nombre d'utilisateurs supprim√©s (nombre excessif de notations, seuil 99e percentile) : 10
Nombre d'utilisateurs supprim√©s (variance des notes < 0.1) : 0
Nombre de films supprim√©s (uniquement notes √† 1.0 ou 5.0) : 11

Nombre total de lignes restantes apr√®s nettoyage : 94285

Aper√ßu des 3 premi√®res lignes apr√®s nettoyage :
   user_id  movie_id  rating  rating_normalized
0      196       242       3                0.5
1      186       302       3                0.5
2       22       377       1                0.0

### Nettoyage de movie.csv

Nous allons proc√©der aux traitements suivants :

Supprimer les colonnes : video_release_date, unknown, IMDb_URL

Action : Retirer les colonnes contenant des informations superflues ou inutiles pour l'analyse.

Pourquoi :

video_release_date est enti√®rement remplie de valeurs manquantes (NaN)

unknown correspond √† un genre peu repr√©sent√© et non significatif

IMDb_URL n‚Äôest pas utile dans le cadre de ce projet

Supprimer les lignes enti√®rement dupliqu√©es en gardant une seule occurrence :

Action : Identifier et √©liminer les lignes identiques

Pourquoi :

Les doublons faussent les statistiques

Cela garantit que chaque film est unique dans le jeu de donn√©es

#### Code : `clean_movies.py`

```python
import pandas as pd

# Chargement du fichier movie.csv
movies = pd.read_csv(r'C:\projet_work\Data-source\movie.csv')

# Suppression des lignes avec dates de sortie manquantes
movies_clean = movies.dropna(subset=['release_date'])

# Suppression des colonnes inutiles
movies_clean = movies_clean.drop(columns=['video_release_date', 'unknown', 'IMDb_URL'])

# Suppression des lignes dupliqu√©es
movies_clean = movies_clean.drop_duplicates(keep='first')

# R√©sum√© du nettoyage
nb_lignes_finales = movies_clean.shape[0]
print(f"Nombre de lignes apr√®s nettoyage : {nb_lignes_finales}\n")

# Aper√ßu des premi√®res lignes
print("Aper√ßu des 3 premi√®res lignes apr√®s nettoyage :")
print(movies_clean.head(3))

# Sauvegarde
movies_clean.to_csv(r'C:\projet_work\Data-source\movie_clean.csv', index=False)
‚ñ∂Ô∏è Ex√©cution du script clean_movies.py
PS C:\projet_work\Script> python clean_movies.py
Nombre de lignes apr√®s nettoyage : 1681
Aper√ßu des 3 premi√®res lignes apr√®s nettoyage :
   movie_id        movie_title release_date  Action  Adventure  Animation  Children's  ...  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western
0         1   Toy Story (1995)  01-Jan-1995       0          0          1           1  ...        0        0        0       0         0    0        0
1         2   GoldenEye (1995)  01-Jan-1995       1          1          0           0  ...        0        0        0       0         1    0        0
2         3  Four Rooms (1995)  01-Jan-1995       0          0          0           0  ...        0        0        0       0         1    0        0

[3 rows x 21 columns]

### Fusion des donn√©es nettoy√©es

Nous allons maintenant proc√©der √† la fusion des donn√©es nettoy√©es.

Dans les 3 scripts ci-dessus, nous allons :

Fusionner les donn√©es nettoy√©es

V√©rifier les movie_id dans ratings non pr√©sents dans movies afin de s‚Äôassurer que toutes les notes se rapportent √† des films existants

V√©rifier les movie_id dans movies non pr√©sents dans ratings afin d‚Äôidentifier les films qui n'ont re√ßu aucune note

Retirer les lignes du fichier ratings avec des movie_id inexistants dans movies

Nettoyer le fichier movies en supprimant les films non not√©s

Fusionner les deux fichiers nettoy√©s ratings_clean et movie_clean sur la colonne movie_id

#### Code : `fusion_donnees.py`

```python
import pandas as pd

# Chargement des fichiers nettoy√©s
movies = pd.read_csv(r'C:\projet_work\Data-source\movie_clean.csv')
ratings = pd.read_csv(r'C:\projet_work\Data-source\clean_rating.csv')

# Fusion des deux fichiers sur la colonne 'movie_id'
merged_data = pd.merge(ratings, movies, on='movie_id', how='inner')

# V√©rification rapide apr√®s fusion
nb_lignes_fusionnees = merged_data.shape[0]
print(f"Nombre total de lignes apr√®s fusion : {nb_lignes_fusionnees}\n")

# Aper√ßu des 3 premi√®res lignes fusionn√©es
print("Aper√ßu des 3 premi√®res lignes apr√®s fusion :")
print(merged_data.head(3))

# Sauvegarde du fichier fusionn√© clairement nomm√© 'merged_data.csv'
merged_data.to_csv(r'C:\projet_work\Data-source\merged_data.csv', index=False)
‚ñ∂Ô∏è Ex√©cution du script fusion_donnees.py
PS C:\projet_work\Script> python fusion_donnees.py
Nombre total de lignes apr√®s fusion : 94276
Aper√ßu des 3 premi√®res lignes apr√®s fusion :
   user_id  movie_id  rating  rating_normalized               movie_title release_date  ...  Mystery  Romance  Sci-Fi  Thriller  War  Western
0      196       242       3                0.5              Kolya (1996)  24-Jan-1997  ...        0        0       0         0    0        0
1      186       302       3                0.5  L.A. Confidential (1997)  01-Jan-1997  ...        1        0       0         1    0        0
2       22       377       1                0.0       Heavyweights (1994)  01-Jan-1994  ...        0        0       0         0    0        0

[3 rows x 24 columns]

#### Code : `verification.py`

```python
import pandas as pd

# Chargement des fichiers nettoy√©s
movies = pd.read_csv(r'C:\projet_work\Data-source\movie_clean.csv')
ratings = pd.read_csv(r'C:\projet_work\Data-source\clean_rating.csv')

# V√©rifier les movie_id dans ratings non pr√©sents dans movies
movies_in_ratings_not_in_movies = ratings[~ratings['movie_id'].isin(movies['movie_id'])]
nb_movies_absents_dans_movies = movies_in_ratings_not_in_movies['movie_id'].nunique()
print(f"Nombre de movie_id pr√©sents dans ratings mais absents dans movies : {nb_movies_absents_dans_movies}")

# Afficher ces movie_id sans correspondance dans movies
print("\nListe des movie_id pr√©sents dans ratings mais absents dans movies :")
print(movies_in_ratings_not_in_movies['movie_id'].unique())

# V√©rifier les movie_id dans movies non pr√©sents dans ratings
movies_not_in_ratings = movies[~movies['movie_id'].isin(ratings['movie_id'])]
nb_movies_absents_dans_ratings = movies_not_in_ratings['movie_id'].nunique()
print(f"\nNombre de movie_id pr√©sents dans movies mais absents dans ratings : {nb_movies_absents_dans_ratings}")

# Afficher ces movie_id sans correspondance dans ratings
print("\nListe des movie_id pr√©sents dans movies mais absents dans ratings :")
print(movies_not_in_ratings['movie_id'].unique())

####  Code : `nettoyage_et_fusion_finale.py`

```python
import pandas as pd

# Chargement initial des donn√©es nettoy√©es
movies = pd.read_csv(r'C:\projet_work\Data-source\movie_clean.csv')
ratings = pd.read_csv(r'C:\projet_work\Data-source\clean_rating.csv')

# --- Nettoyage ratings : suppression des movie_id sans correspondance ---
ratings_final = ratings[ratings['movie_id'].isin(movies['movie_id'])]
nb_lignes_supprimees_rating = ratings.shape[0] - ratings_final.shape[0]
print(f"Lignes supprim√©es de ratings (movie_id sans correspondance) : {nb_lignes_supprimees_rating}")

# --- Nettoyage movies : suppression des films sans notation ---
movies_final = movies[movies['movie_id'].isin(ratings_final['movie_id'])]
nb_films_supprimes_movie = movies.shape[0] - movies_final.shape[0]
print(f"Films supprim√©s dans movies (aucune notation associ√©e) : {nb_films_supprimes_movie}\n")

# V√©rification des r√©sultats finaux
print(f"Nombre final de lignes dans ratings : {ratings_final.shape[0]}")
print(f"Nombre final de films dans movies : {movies_final.shape[0]}\n")

# --- Fusion des deux fichiers nettoy√©s ---
merged_final_data = pd.merge(ratings_final, movies_final, on='movie_id', how='inner')

# V√©rification apr√®s fusion finale
print(f"Nombre total de lignes apr√®s fusion : {merged_final_data.shape[0]}\n")
print("Aper√ßu des 3 premi√®res lignes fusionn√©es :")
print(merged_final_data.head(3))

# Sauvegarde d√©finitive
‚ñ∂Ô∏è Ex√©cution du script nettoyage_et_fusion_finale.py
PS C:\projet_work\Script> python nettoyage_et_fusion_finale.py
Lignes supprim√©es de ratings (movie_id sans correspondance) : 9
Films supprim√©s dans movies (aucune notation associ√©e) : 221
Nombre final de lignes dans ratings : 94276
Nombre final de films dans movies : 1460
Nombre total de lignes apr√®s fusion : 94276
Aper√ßu des 3 premi√®res lignes fusionn√©es :
   user_id  movie_id  rating  rating_normalized               movie_title release_date  ...  Mystery  Romance  Sci-Fi  Thriller  War  Western
0      196       242       3                0.5              Kolya (1996)  24-Jan-1997  ...        0        0       0         0    0        0
1      186       302       3                0.5  L.A. Confidential (1997)  01-Jan-1997  ...        1        0       0         1    0        0
2       22       377       1                0.0       Heavyweights (1994)  01-Jan-1994  ...        0        0       0         0    0        0

[3 rows x 24 columns]


```markdown

## III. Phase d‚ÄôAnalyse Exploratoire

L'objectif de cette Exploration de Donn√©es est de plonger au c≈ìur de nos donn√©es de films et de notes pour en extraire des informations pr√©cieuses. En comprenant les tendances, les distributions et les relations au sein de nos donn√©es, nous pourrons construire un syst√®me de recommandation de films plus performant et mieux adapt√© aux pr√©f√©rences des utilisateurs.

Dans ce projet, nous formulons plusieurs hypoth√®ses que nous allons chercher √† valider √† travers cette √©tude :

‚Ä¢ Hypoth√®se 1 : Les utilisateurs ayant des notations similaires pour les m√™mes films partagent des go√ªts proches.  
‚Ä¢ Hypoth√®se 2 : Les genres sont des indicateurs fiables pour d√©terminer la similarit√© entre films.  
‚Ä¢ Hypoth√®se 3 : Les tendances globales des notations peuvent √™tre utilis√©es pour guider les recommandations, notamment pour les nouveaux utilisateurs.

Notre analyse se d√©roulera en plusieurs √©tapes cl√©s, con√ßues pour nous aider √† tester ces hypoth√®ses et √† mieux comprendre nos donn√©es :

1. Analyse des Films  
2. Analyse des Notes  
3. Analyse des Genres  
4. Analyse des Utilisateurs

Chaque √©tape nous permettra de mieux comprendre nos donn√©es, de tester nos hypoth√®ses et de mettre en lumi√®re les informations pertinentes pour la construction de notre syst√®me de recommandation.

### 1. Analyse des Films

Nous allons lister les points √† faire ressortir et les graphiques d‚Äôillustration :

- Nombre total de films uniques  
- R√©partition des films par ann√©e de sortie  
- Top 10 films les plus not√©s  
- Calcul des films les mieux not√©s avec plus de 50 notes  
- Calcul du nombre de genres par film  
- Top 10 films avec le plus de genres  
- Distribution des films en fonction du nombre de genres auxquels ils appartiennent (mono-genre vs multi-genres)

**Graphiques produits :**

- R√©partition des films par ann√©e de sortie (graphique √† barres)  
- Top 10 films les plus not√©s (graphique √† barres horizontales)  
- Top 10 des films les mieux not√©s (> 50 notes) (graphique √† barres horizontales)  
- Top 10 des films avec le plus de genres (graphique √† barres horizontales)  
- Distribution des films mono-genre vs multi-genres (diagramme circulaire)
####  Code : `analyse_films.py`

```python
import pandas as pd
import matplotlib.pyplot as plt

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
data['release_date'] = pd.to_datetime(data['release_date'])

# Nombre total de films uniques
total_films = data['movie_id'].nunique()
print(f"Nombre total de films : {total_films}")

# R√©partition des films par ann√©e
films_par_annee = data[['movie_id', 'release_date']].drop_duplicates().groupby(data['release_date'].dt.year).count()['movie_id']
films_par_annee.plot(kind='bar', color='skyblue')
plt.title('Nombre de films par ann√©e de sortie')
plt.xlabel('Ann√©e de sortie')
plt.ylabel('Nombre de films')
plt.tight_layout()
plt.show()

# Top 10 films les plus not√©s
top_films_notes = data['movie_title'].value_counts().head(10)
top_films_notes.plot(kind='barh', color='salmon')
plt.title('Top 10 des films les plus not√©s')
plt.xlabel('Nombre de notes')
plt.tight_layout()
plt.gca().invert_yaxis()
plt.show()

# Films les mieux not√©s (> 50 notes)
ratings_stats = data.groupby('movie_title')['rating'].agg(['mean', 'count'])
films_mieux_notes = ratings_stats[ratings_stats['count'] > 50].sort_values('mean', ascending=False).head(10)
films_mieux_notes['mean'].plot(kind='barh', color='limegreen')
plt.title('Top 10 des films les mieux not√©s (> 50 notes)')
plt.xlabel('Note moyenne')
plt.tight_layout()
plt.gca().invert_yaxis()
plt.xlim(3, 5)
plt.show()

# Films multi-genres
genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

films_genres = data[['movie_id', 'movie_title'] + genres].drop_duplicates()
films_genres['nombre_genres'] = films_genres[genres].sum(axis=1)
films_multi_genres = films_genres.sort_values('nombre_genres', ascending=False).head(10)
films_multi_genres.set_index('movie_title')['nombre_genres'].plot(kind='barh', color='orchid')
plt.title('Top 10 des films avec le plus de genres')
plt.xlabel('Nombre de genres')
plt.tight_layout()
plt.gca().invert_yaxis()
plt.show()

# Distribution mono-genre vs multi-genres
distribution = films_genres['nombre_genres'].apply(lambda x: 'Mono-genre' if x==1 else 'Multi-genres').value_counts()
distribution.plot(kind='pie', autopct='%1.1f%%', colors=['gold','deepskyblue'], explode=[0, 0.05])
plt.title('Distribution des films mono-genre vs multi-genres')
plt.ylabel('')
plt.tight_layout()
plt.show()


```markdown
#### ‚ñ∂Ô∏è R√©sultats utiles du script `analyse_films.py`

```text
Nombre total de films : 1460

R√©partition des films par ann√©e (10 premi√®res lignes) :
1922    1
1930    1
1931    1
1932    1
1933    1
1934    4
1935    3
1936    2
1937    3
1938    3

Top 10 des films les plus not√©s :
Star Wars (1977)                 573  
Contact (1997)                   500  
Fargo (1996)                     499  
Return of the Jedi (1983)        497  
Liar Liar (1997)                 476  
English Patient, The (1996)      474  
Scream (1996)                    468  
Toy Story (1995)                 443  
Air Force One (1997)             423  
Independence Day (ID4) (1996)    421  

Top 10 des films les mieux not√©s (ayant > 50 notes) :
Wrong Trousers, The (1993)                          4.50  
Close Shave, A (1995)                               4.49  
Schindler's List (1993)                             4.47  
Casablanca (1942)                                   4.46  
Shawshank Redemption, The (1994)                    4.45  
Wallace & Gromit: Best of Aardman...                4.44  
Usual Suspects, The (1995)                          4.40  
Third Man, The (1949)                               4.40  
Rear Window (1954)                                  4.39  
12 Angry Men (1957)                                 4.36  

Top 10 films multi-genres :
Transformers: The Movie (1986)    6  
Kid in King Arthur's Court (1995) 6  
Empire Strikes Back, The (1980)   6  
Return of the Jedi (1983)         5  
Diva (1981)                        5  
Star Wars (1977)                  5  
Army of Darkness (1993)           5  
Heavy Metal (1981)                5  
Pagemaster, The (1994)            5  
From Dusk Till Dawn (1996)        5  

Distribution mono-genre vs multi-genres :
Multi-genres : 781  
Mono-genre   : 679

```markdown
#####  Analyse br√®ve des r√©sultats

- Le dataset comporte un total de **1460 films uniques** apr√®s nettoyage.

**R√©partition des films par ann√©e :**  
- Les ann√©es 1922 √† 1938 pr√©sentent un nombre tr√®s faible de films (entre 1 et 4 par ann√©e), ce qui indique que la majorit√© des films du dataset sont probablement plus r√©cents.

**Top 10 des films les plus not√©s :**  
- *Star Wars (1977)* arrive clairement en t√™te avec 573 notes, suivi par *Contact (1997)* et *Fargo (1996)*.  
- Ces films sont principalement issus des ann√©es 1990 et correspondent √† de grands succ√®s populaires.

**Films les mieux not√©s (> 50 notes) :**  
- *The Wrong Trousers (1993)* (4.50) et *A Close Shave (1995)* (4.49) dominent, tous deux √©tant des films d‚Äôanimation.  
- Des classiques comme *Schindler's List*, *Casablanca* et *Shawshank Redemption* figurent en haut du classement.

**Films multi-genres :**  
- Certains films sont class√©s dans **jusqu‚Äô√† 6 genres diff√©rents**, comme *Transformers (1986)* ou *The Empire Strikes Back (1980)*.

**Distribution mono-genre vs multi-genres :**  
- 781 films (53%) sont multi-genres contre 679 (47%) mono-genre.  
- Cette r√©partition √©quilibr√©e souligne que **la majorit√© des films combinent plusieurs genres**, ce qui peut enrichir les recommandations futures.

#### Graphiques produits

**1. Nombre de films par ann√©e de sortie**  
![Nombre de films par ann√©e](EDA/film_par_annee.png)  
_On remarque clairement une augmentation significative du nombre de films √† partir des ann√©es 1980, avec un pic majeur dans les ann√©es 1990 (en particulier autour de 1995-1997). Cela confirme que le jeu de donn√©es est principalement constitu√© de films r√©cents, ce qui est coh√©rent avec le classement des films les plus not√©s (majoritairement des ann√©es 1990)._

**2. Top 10 des films les plus not√©s**  
![Top 10 des films les plus not√©s](EDA/Top10_Films_plus_notes.png)  
_On retrouve essentiellement des blockbusters (films √† tr√®s grand succ√®s commercial et populaire) des ann√©es 1990 tels que ¬´ Star Wars (1977) ¬ª, ¬´ Contact (1997) ¬ª, et ¬´ Fargo (1996) ¬ª. Ce graphique est coh√©rent avec le graphique par ann√©e de sortie, qui montre que les films r√©cents attirent le plus d‚Äôattention et de notations de la part des utilisateurs._

**3. Top 10 des films les mieux not√©s**  
![Top 10 des films les mieux not√©s](EDA/Top10_films_ mieux_notes.png) 
_Les films les mieux not√©s sont des grands classiques ou films unanimement appr√©ci√©s, tels que ¬´ Wrong Trousers (1993) ¬ª, ¬´ Schindler's List (1993) ¬ª et ¬´ Casablanca (1942) ¬ª. Ce graphique r√©v√®le clairement que les utilisateurs notent g√©n√©ralement tr√®s hautement les classiques reconnus, ind√©pendamment de leur anciennet√©._

**4. Top 10 des films avec le plus de genres**  
![Top 10 des films avec le plus de genres](EDA/Top10_films_ plus_de_genres.png)  
_Des films tels que ¬´ Transformers (1986) ¬ª et ¬´ Empire Strikes Back (1980) ¬ª apparaissent en t√™te avec jusqu'√† 6 genres diff√©rents. Cela montre une difficult√© √† classifier pr√©cis√©ment ces films dans une seule cat√©gorie et explique aussi leur large audience et leur popularit√©._

**5. Distribution des films mono-genre vs multi-genres**  
![Distribution mono vs multi genres](EDA/mono_vs_multi.png) 
_Le graphique r√©v√®le une r√©partition relativement √©quilibr√©e : 53,5% multi-genres et 46,5% mono-genre. Cette r√©partition indique une grande diversit√© dans la cat√©gorisation des films, qui se refl√®te dans la popularit√© vari√©e des films et explique pourquoi certains films apparaissent dans les tops de plusieurs genres._
### 2. Analyse des Notes

Cette √©tape vise √† comprendre la distribution des √©valuations attribu√©es par les utilisateurs, √† d√©tecter des comportements de notation particuliers, et √† identifier des tendances temporelles ou structurelles dans les notations.

**Les points √† faire ressortir sont :**

- Le nombre total de notes dans le jeu de donn√©es.
- Les statistiques descriptives de la colonne `rating` (moyenne, m√©diane, √©cart-type, etc.)
- Le nombre moyen de notes par film.
- La note moyenne des films pour chaque ann√©e.
- Comparaison des notes moyennes des films anciens et r√©cents.

**Graphiques produits :**

- Histogramme de la distribution des notes  
- Distribution du nombre de notes par film  
- √âvolution des notes moyennes par ann√©e  
- Moyenne des notes : films anciens vs r√©cents
####  Code : `analyse_notes.py`

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Nombre total de notes
total_notes = data.shape[0]
print(f"Nombre total de notes dans la base : {total_notes}")

# Statistiques descriptives des notes
stats_notes = data['rating'].describe()
print("\nStatistiques descriptives des notes :")
print(stats_notes)

# Histogramme de la distribution des notes
plt.figure(figsize=(8,5))
sns.histplot(data['rating'], bins=5, kde=True)
plt.title('Distribution des notes utilisateurs')
plt.xlabel('Notes')
plt.ylabel('Fr√©quence')
plt.tight_layout()
plt.show()

# Nombre moyen de notes par film
notes_par_film = data.groupby('movie_id').size()
moyenne_notes_film = notes_par_film.mean().round(2)
print(f"\nNombre moyen de notes par film : {moyenne_notes_film}")

# Distribution du nombre de notes par film
plt.figure(figsize=(8,5))
sns.histplot(notes_par_film, bins=30, kde=True, color='lightcoral')
plt.title('Distribution du nombre de notes par film')
plt.xlabel('Nombre de notes')
plt.ylabel('Nombre de films')
plt.tight_layout()
plt.show()

# Note moyenne par ann√©e
data['release_date'] = pd.to_datetime(data['release_date'])
data['release_year'] = data['release_date'].dt.year
note_par_annee = data.groupby('release_year')['rating'].mean()
print("\nNote moyenne des films par ann√©e (10 premi√®res lignes):")
print(note_par_annee.head(10))

plt.figure(figsize=(12,5))
note_par_annee.plot(marker='o', linestyle='-', color='teal')
plt.title('√âvolution de la note moyenne des films par ann√©e')
plt.xlabel('Ann√©e de sortie')
plt.ylabel('Note moyenne')
plt.grid(True)
plt.tight_layout()
plt.show()

# Films anciens vs r√©cents
data['age_group'] = data['release_year'].apply(lambda x: 'Ancien (<1980)' if x < 1980 else 'R√©cent (>=1980)')
notes_age_group = data.groupby('age_group')['rating'].mean()
print("\nNote moyenne des films selon anciennet√© :")
print(notes_age_group)

plt.figure(figsize=(7,5))
notes_age_group.plot(kind='bar', color=['orange','dodgerblue'])
plt.title('Note moyenne : films anciens vs r√©cents')
plt.ylabel('Note moyenne')
plt.xlabel('Cat√©gorie de film')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()
#### ‚ñ∂Ô∏è R√©sultats utiles du script `analyse_notes.py`

```text
Nombre total de notes dans la base : 94276

Statistiques descriptives des notes :
count    94276.000000  
mean         3.556547  
std          1.112641  
min          1.000000  
25%          3.000000  
50%          4.000000  
75%          4.000000  
max          5.000000  

Nombre moyen de notes par film : 64.57

Note moyenne des films par ann√©e (10 premi√®res lignes) :
1922    3.580000  
1930    3.875000  
1931    4.075000  
1932    3.833333  
1933    4.034483  
1934    4.033557  
1935    3.931034  
1936    3.727273  
1937    3.739130  
1938    3.894180  

Note moyenne des films selon anciennet√© :
Ancien (<1980)     3.923824  
R√©cent (>=1980)    3.478773
####  Graphiques produits

**1. Distribution des notes utilisateurs**  
![Distribution des notes](EDA/notes_user.png) 

**2. Distribution du nombre de notes par films**  
![Nombre de notes par film](EDA/nombre_notes_par_films.png) 

**3. √âvolution des notes moyennes des films par ann√©e**  
![Notes moyennes par ann√©e](EDA/notes_moyennes_par_annee.png) 

**4. Note moyenne : films anciens vs r√©cents**  
![Ancien vs r√©cent](EDA/films_anciens_vs_recents.png) films_anciens_vs_recents.png
###  Synth√®se des r√©sultats et graphiques (`analyse_notes.py`)

**Nombre total et distribution des notes :**
- Le dataset contient 94 276 notations, avec une moyenne g√©n√©rale de 3,56/5.
- La majorit√© des notes attribu√©es par les utilisateurs se situe entre 3 et 4, indiquant une tendance g√©n√©rale plut√¥t positive dans les √©valuations.

**Distribution du nombre de notes par film :**
- La majorit√© des films ont tr√®s peu de notes (moins de 50 notes), ce qui est typique d'un tel jeu de donn√©es o√π seuls quelques films tr√®s populaires concentrent une grande quantit√© de notations.
- Quelques rares films atteignent un nombre tr√®s √©lev√© de notes (jusqu'√† environ 600 notes, comme vu pr√©c√©demment avec ¬´ Star Wars (1977) ¬ª).

**√âvolution des notes moyennes par ann√©e :**
- Les films plus anciens (entre 1930-1960) obtiennent g√©n√©ralement des notes moyennes plus √©lev√©es.
- √Ä partir des ann√©es 1980-1990, on remarque une nette baisse progressive des notes moyennes attribu√©es aux films, potentiellement due √† une diversit√© croissante de genres et √† une audience plus large et critique.

**Note moyenne : films anciens vs r√©cents :**
- Les films anciens (avant 1980) obtiennent une note moyenne plus √©lev√©e (3,92) comparativement aux films r√©cents (apr√®s 1980), not√©s en moyenne √† 3,48.

---

### 3. Analyse des Genres

**Les points √† faire ressortir sont :**

- Le nombre de films pour chaque genre.
- La note moyenne des films pour chaque genre.
- L'√©volution de genres sp√©cifiques (par exemple, "Sci-Fi" et "Drama") au fil des d√©cennies.
- La corr√©lation entre les diff√©rents genres.

**Graphiques produits :**

- Un graphique √† barres pour visualiser le nombre de films dans chaque genre.  
- Un graphique √† barres pour visualiser la note moyenne des films pour chaque genre.  
- Un graphique lin√©aire pour visualiser l'√©volution de genres sp√©cifiques au fil du temps (par d√©cennie).  
- Une heatmap pour visualiser la matrice de corr√©lation entre les diff√©rents genres.

####  Code : `analyse_genres.py`

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Conversion date de sortie en datetime
data['release_date'] = pd.to_datetime(data['release_date'])
data['release_year'] = data['release_date'].dt.year

genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

# ----------------------- Nombre de films par genre ------------------------
nb_films_genre = {genre: data[data[genre]==1]['movie_id'].nunique() for genre in genres}
nb_films_genre_series = pd.Series(nb_films_genre).sort_values(ascending=False)
print("Nombre de films par genre :")
print(nb_films_genre_series)

plt.figure(figsize=(12,6))
sns.barplot(y=nb_films_genre_series.index, x=nb_films_genre_series.values, palette='mako')
plt.xlabel('Nombre de films')
plt.ylabel('Genre')
plt.title('Nombre de films par genre')
plt.tight_layout()
plt.show()

# ----------------------- Notes moyennes par genre ------------------------
note_genres = {genre: data[data[genre]==1]['rating'].mean() for genre in genres}
note_genres_series = pd.Series(note_genres).sort_values(ascending=False)
print("\nNote moyenne par genre :")
print(note_genres_series)

plt.figure(figsize=(12,6))
sns.barplot(y=note_genres_series.index, x=note_genres_series.values, palette='viridis')
plt.xlabel('Note moyenne')
plt.ylabel('Genre')
plt.title('Note moyenne par genre')
plt.xlim(3,5)
plt.tight_layout()
plt.show()

# ----------------------- √âvolution des genres dans le temps ------------------------
data['decade'] = (data['release_year']//10)*10
genres_temps = data.groupby('decade')[['Sci-Fi','Drama']].sum()
print("\n√âvolution des genres 'Sci-Fi' et 'Drama' par d√©cennie :")
print(genres_temps)

genres_temps.plot(kind='line', marker='o', figsize=(10,5))
plt.title('√âvolution des genres Sci-Fi et Drama par d√©cennie')
plt.xlabel('D√©cennie')
plt.ylabel('Nombre de films')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------- Corr√©lation entre genres ------------------------
correlation_genres = data[genres].corr()
print("\nCorr√©lation entre genres (extrait) :")
print(correlation_genres.head())

plt.figure(figsize=(14,10))
sns.heatmap(correlation_genres, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Heatmap des corr√©lations entre genres')
plt.tight_layout()
plt.show()

#### ‚ñ∂Ô∏è R√©sultats du script `analyse_genres.py`

```text
Nombre de films par genre :
Drama          608
Comedy         456
Thriller       230
Romance        228
Action         227
Adventure      130
Children's     119
Sci-Fi          97
Crime           93
Horror          83
War             68
Mystery         57
Musical         55
Animation       42
Documentary     30
Western         25
Film-Noir       21
Fantasy         20

Note moyenne par genre :
Film-Noir      3.946111
War            3.829705
Documentary    3.767267
Drama          3.717208
Mystery        3.655869
Crime          3.655019
Romance        3.642316
Western        3.641748
Animation      3.595398
Sci-Fi         3.576115
Thriller       3.529304
Musical        3.529098
Adventure      3.521315
Action         3.499489
Comedy         3.415981
Children's     3.378061
Horror         3.337219
Fantasy        3.230648

√âvolution des genres 'Sci-Fi' et 'Drama' par d√©cennie :
        Sci-Fi  Drama
decade
1920         0      0
1930         0    637
1940         0    740
1950       263   1217
1960       536   1278
1970      1265   1517
1980      3044   4682
1990      7117  27423

Corr√©lation entre genres (extrait) :
              Action  Adventure  Animation  Children's    Comedy     Crime  ...   Mystery   Romance    Sci-Fi  Thriller       War   Western
Action      1.000000   0.453562  -0.101185   -0.147025 -0.225300  0.005314  ... -0.033760 -0.018278  0.324754  0.249892  0.167365  0.063701
Adventure   0.453562   1.000000  -0.026709    0.096590 -0.112925 -0.031725  ... -0.044118 -0.017517  0.295197 -0.051587  0.087986  0.011085
Animation  -0.101185  -0.026709   1.000000    0.558514  0.032727 -0.057732  ... -0.046010 -0.086526 -0.047056 -0.078560 -0.057961 -0.026649
Children's -0.147025   0.096590   0.558514    1.000000  0.086271 -0.082387  ... -0.055738 -0.119693 -0.044201 -0.144973 -0.086481 -0.031909
Comedy     -0.225300  -0.112925   0.032727    0.086271  1.000000 -0.091057  ... -0.112975  0.094760 -0.146919 -0.292629 -0.121855  0.002660
...

#### Graphiques produits

**1. Nombre de films par genre**  
![Nombre de films par genre](EDA/film_par_genre.png)      

_Le genre ¬´ Drama ¬ª domine largement avec le plus grand nombre de films, suivi par Comedy, Action et Thriller. √Ä l‚Äôinverse, les genres comme Film-Noir ou Fantasy sont nettement sous-repr√©sent√©s. Ceci montre que le jeu de donn√©es privil√©gie les films √† large audience et grand public._

**2. Note moyenne par genre**  
![Note moyenne par genre](EDA/Note_par_genre.png)  
_Les genres comme Film-Noir, War et Documentary obtiennent les notes moyennes les plus √©lev√©es (>3.7). √Ä l‚Äôoppos√©, les genres Horror, Children‚Äôs et Comedy obtiennent des notes moyennes plus basses. On en conclut que les utilisateurs valorisent davantage les genres sp√©cialis√©s, s√©rieux ou classiques (comme Film-Noir, Documentary) par rapport aux genres tr√®s populaires._

**3. √âvolution des genres Sci-Fi et Drama par d√©cennie**  
![√âvolution des genres](EDA/scifi_drama_par_decennie.png)  
_Le genre ¬´ Drama ¬ª conna√Æt une forte augmentation des ann√©es 1980-1990, avec une croissance exponentielle en popularit√©. Sci-Fi augmente √©galement fortement √† partir des ann√©es 1980, mais reste toujours inf√©rieur en nombre √† Drama. Ce r√©sultat refl√®te clairement l'int√©r√™t croissant pour ces deux genres, surtout le ¬´ Drama ¬ª dans les d√©cennies r√©centes._

**4. Heatmap des corr√©lations entre genres**  
![Corr√©lation entre genres](EDA/heatmap.png)  
_La heatmap montre clairement que certains genres sont fr√©quemment associ√©s. Par exemple :  
- Action & Adventure (forte corr√©lation : 0.45)  
- Animation & Children's (forte corr√©lation, logique puisque ces deux genres sont souvent destin√©s au m√™me public)  
Inversement, des genres comme Film-Noir et Fantasy sont peu associ√©s √† d‚Äôautres, confirmant leur caract√®re sp√©cifique.
### 4. Analyse des Utilisateurs

Cette analyse vise √† comprendre les comportements des utilisateurs en mati√®re de notation, en identifiant ceux qui attribuent le plus de notes, la distribution de leurs √©valuations et la variance de leurs pr√©f√©rences.

#### Points √† analyser :
- **Nombre total d'utilisateurs uniques dans le jeu de donn√©es**
- **Nombre moyen de notes attribu√©es par utilisateur**
- **Top 10 des utilisateurs ayant attribu√© le plus grand nombre de notes**
- **Distribution du nombre de notes attribu√©es par utilisateur**
- **Variance et moyenne des notes attribu√©es par utilisateur**

#### Graphiques produits :
- üîπ **Top 10 des utilisateurs ayant attribu√© le plus de notes**  
- üîπ **Histogramme de la distribution des notes moyennes par utilisateur**  
- üîπ **Histogramme de la distribution des variances des notes attribu√©es par les utilisateurs**
---

#### Code : `analyse_utilisateurs.py`

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Nombre total d‚Äôutilisateurs
total_users = data['user_id'].nunique()
print(f"Nombre total d'utilisateurs : {total_users}")

# Nombre moyen de notes par utilisateur
notes_par_utilisateur = data.groupby('user_id').size()
moyenne_notes_user = notes_par_utilisateur.mean().round(2)
print(f"\nNombre moyen de notes par utilisateur : {moyenne_notes_user}")

# Utilisateurs les plus actifs
top_utilisateurs_actifs = notes_par_utilisateur.sort_values(ascending=False).head(10)
print("\nTop 10 utilisateurs les plus actifs :")
print(top_utilisateurs_actifs)

# Graphique: Top 10 utilisateurs les plus actifs
plt.figure(figsize=(10,5))
top_utilisateurs_actifs.plot(kind='bar', color='skyblue')
plt.title('Top 10 utilisateurs les plus actifs')
plt.xlabel('User ID')
plt.ylabel('Nombre de notes')
plt.tight_layout()
plt.show()

# Distribution du nombre de notes par utilisateur
plt.figure(figsize=(10,5))
sns.histplot(notes_par_utilisateur, bins=50, kde=True, color='green')
plt.title('Distribution du nombre de notes par utilisateur')
plt.xlabel('Nombre de notes donn√©es')
plt.ylabel('Nombre d\'utilisateurs')
plt.tight_layout()
plt.show()

# Variance et Moyenne des notes par utilisateur
stats_users = data.groupby('user_id')['rating'].agg(['mean','var'])
print("\nStatistiques (moyenne et variance) des notes par utilisateur (10 premiers) :")
print(stats_users.head(10))

# Graphique: Distribution des moyennes des notes par utilisateur
plt.figure(figsize=(10,5))
sns.histplot(stats_users['mean'], bins=30, kde=True, color='orange')
plt.title('Distribution des moyennes de notes par utilisateur')
plt.xlabel('Moyenne des notes')
plt.ylabel('Nombre d\'utilisateurs')
plt.tight_layout()
plt.show()

# Graphique: Distribution des variances des notes par utilisateur
plt.figure(figsize=(10,5))
sns.histplot(stats_users['var'].dropna(), bins=30, kde=True, color='red')
plt.title('Distribution des variances des notes par utilisateur')
plt.xlabel('Variance des notes')
plt.ylabel('Nombre d\'utilisateurs')
plt.tight_layout()
plt.show()

---

####  R√©sultats utiles du script `analyse_utilisateurs.py`

```text
Nombre total d'utilisateurs : 933

Nombre moyen de notes par utilisateur : 101.05

Top 10 utilisateurs les plus actifs :
user_id
279    424
429    414
181    406
846    405
94     400
7      400
682    398
308    396
92     388
293    388

Statistiques (moyenne et variance) des notes par utilisateur (10 premiers) :
             mean       var
user_id
1        3.603704  1.600730
2        3.754098  0.955191
3        2.796296  1.486024
4        4.333333  0.840580
5        2.889535  1.841527
6        3.635071  1.080478
7        3.975000  1.117168
8        3.796610  1.544126
9        4.272727  0.874459
10       4.207650  0.341260
####  Graphiques produits

**1. Top 10 des utilisateurs ayant attribu√© le plus de notes**  
![Top utilisateurs actifs](EDA/Top10_users_actifs.png)  

**2. Distribution du nombre de notes par utilisateur**  
![Distribution des notes par utilisateur](EDA/notes_par_user.png)  

**3. Histogramme de la distribution des moyennes des notes par utilisateur**  
![Moyenne des notes par utilisateur](EDA/moyennes_notes_user.png)  

**4. Histogramme de la distribution des variances des notes par utilisateur**  
![Variance des notes par utilisateur](EDA/variances_notes_user.png)  

---

#### Analyse des r√©sultats

**Activit√© et nombre de notes par utilisateur :**  
- Le dataset comporte **933 utilisateurs**, qui attribuent en moyenne **101 notes chacun**, ce qui indique une **forte activit√© moyenne** par utilisateur.
- Cependant, la distribution montre que **beaucoup d‚Äôutilisateurs notent relativement peu de films**, tandis que **seuls quelques utilisateurs tr√®s actifs notent √©norm√©ment de films** (jusqu‚Äô√† plus de **400 films not√©s** pour les utilisateurs les plus actifs).

**Utilisateurs les plus actifs :**  
- Les **10 utilisateurs les plus actifs** notent **entre 388 et 424 films**, r√©v√©lant **un engagement tr√®s √©lev√©** avec la plateforme.

**Distribution des moyennes de notes par utilisateur :**  
- La majorit√© des utilisateurs ont une **moyenne de notes situ√©e entre 3 et 4**, ce qui sugg√®re un **comportement g√©n√©ralement positif et peu critique** des utilisateurs envers les films.
- Cette observation rejoint directement la **distribution g√©n√©rale des notes** vue dans les analyses pr√©c√©dentes.

**Distribution des variances des notes par utilisateur :**  
- La **variance des notes attribu√©es par utilisateur** est g√©n√©ralement comprise **entre 0,5 et 1,5**, ce qui signifie que la plupart des utilisateurs **donnent des notes vari√©es mais mod√©r√©es**.
- Peu d‚Äôutilisateurs sont **extr√™mement constants (faible variance)** ou **extr√™mement vari√©s dans leurs notes (haute variance)**.

---
## üìå Conclusion

Les r√©sultats obtenus √† travers l‚Äôanalyse exploratoire confirment clairement la pertinence des hypoth√®ses formul√©es :

### ‚úÖ Hypoth√®se 1 (Similarit√© utilisateurs) :
Les distributions des moyennes et variances des notes indiquent que **certains utilisateurs partagent effectivement des go√ªts similaires**, ce qui est une base solide pour les syst√®mes de recommandation bas√©s sur le **filtrage collaboratif**.

### ‚úÖ Hypoth√®se 2 (Genres indicateurs fiables) :
Les **corr√©lations fortes entre certains genres** confirment que **les genres constituent des crit√®res pertinents pour mesurer la similarit√© entre films**, ce qui est exploitable pour un mod√®le bas√© sur le **contenu**.

### ‚úÖ Hypoth√®se 3 (Tendances globales) :
Les **tendances temporelles et globales des notes** montrent clairement qu'il existe des **pr√©f√©rences dominantes** exploitables pour guider les recommandations, notamment pour les nouveaux utilisateurs.

---

## Perspectives : Vers une Mod√©lisation plus avanc√©e

Toutefois, pour **valider rigoureusement ces hypoth√®ses et am√©liorer les recommandations**, il serait pertinent d‚Äôutiliser des approches plus avanc√©es :

### üîπ **1. Filtrage Collaboratif**  
- Confirmer plus pr√©cis√©ment la **similarit√© entre utilisateurs** selon leurs notations.  
- Fournir des recommandations **bas√©es sur les go√ªts d‚Äôutilisateurs proches**.

### üîπ **2. Mod√®les bas√©s sur le Contenu**  
- Valider l‚Äôutilit√© des **genres** comme crit√®re d√©terminant de similarit√© entre films.  
- Exploiter les **m√©tadonn√©es des films** pour des recommandations plus pr√©cises.

### üîπ **3. Mod√®le Hybride**  
- Combiner **Filtrage Collaboratif** et **Mod√®les bas√©s sur le Contenu**.  
- Tirer parti des **forces des deux approches** pour am√©liorer la pertinence des recommandations.

---

### **Prochaine √©tape : Impl√©mentation des mod√®les de recommandation**
L‚Äô√©tape suivante consistera √† **impl√©menter et √©valuer ces mod√®les** pour proposer un **syst√®me de recommandation efficace et personnalis√©** aux utilisateurs.
## IV & V. Phase de Mod√©lisation et d‚Äô√âvaluation

Pour cette phase de mod√©lisation du projet, j'ai opt√© pour l'algorithme **KNN (K-Nearest Neighbors)** en raison de sa **simplicit√©** et de sa **robustesse** pour mesurer directement la **similarit√© entre utilisateurs ou films**.

Selon le mod√®le, le choix de la mesure de similarit√© a √©t√© adapt√© :

- **Content-Based (Bas√© sur le Contenu) :**  
  - **Mesure utilis√©e :** **Distance Cosinus**  
  - Pourquoi ? ‚Üí Permet de comparer efficacement les **vecteurs de caract√©ristiques (genres de films)**.

- **Collaboratif (User-User et Item-Item) :**  
  - **Mesures test√©es :** **Distances Euclidienne & Manhattan**  
  - Pourquoi ? ‚Üí Ces distances se sont r√©v√©l√©es **particuli√®rement performantes** pour capturer les variations des notations.

---

### Processus de Mod√©lisation

Pour chaque approche, j'ai suivi un processus **structur√©** comprenant :

1Ô∏è‚É£ **Pr√©paration des donn√©es**  
   - Cr√©ation de matrices **Utilisateur-Film** et **Film-Utilisateur**.  
   - Extraction des **caract√©ristiques de contenu**.

2Ô∏è‚É£ **Entra√Ænement du mod√®le KNN**   
   - Optimisation des **hyperparam√®tres**.  
   - Test de diff√©rentes **mesures de distance**.

3Ô∏è‚É£ **√âvaluation du mod√®le**   
   - **M√©trique utilis√©e :** **RMSE (Root Mean Squared Error)**.  
   - S√©lection du **mod√®le le plus performant**.  

 **R√©sultat final :**  
**Le mod√®le Item-Item KNN s'est av√©r√© √™tre le plus performant.**  
Il a √©t√© **d√©ploy√© dans une application interactive et une API**, garantissant ainsi **des recommandations pertinentes et fiables**.

---

## üîπ f. Pr√©paration des donn√©es pour la matrice utilisateur-item

Cette matrice repr√©sente les **interactions utilisateur-film**, o√π **chaque cellule** indique la **note donn√©e par un utilisateur √† un film**.  

‚úÖ **Objectif :** Transformer les **donn√©es brutes** (utilisateurs, films, notes) en une **structure matricielle optimis√©e**, facilitant :
- L‚Äôanalyse des relations entre films et utilisateurs.
- L‚Äôapplication d‚Äôalgorithmes de recommandation bas√©s sur la **similarit√©**.

---

####  Code : `preparation_matrice.py`

```python
import pandas as pd

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Cr√©ation de la matrice User-Item
user_item_matrix = data.pivot_table(index='user_id', columns='movie_title', values='rating').fillna(0)

# Sauvegarde de la matrice
user_item_matrix.to_csv(r'C:\projet_work\Data-source\user_item_matrix.csv')

print("Matrice User-Item cr√©√©e avec succ√®s.")

## üîπ g. Impl√©mentation de KNN pour le Filtrage Collaboratif

Le **filtrage collaboratif** repose sur le principe que **des utilisateurs ayant exprim√© des pr√©f√©rences similaires dans le pass√© continueront de partager des go√ªts comparables √† l'avenir**.  

Pour mettre en ≈ìuvre ce concept, **deux mod√®les distincts** ont √©t√© d√©velopp√©s :

### 1Ô∏è‚É£ **Mod√®le User-User (Collaboratif bas√© sur les utilisateurs)**
üîπ **Principe :** Identifie les utilisateurs ayant un comportement similaire.  
üîπ **Recommandation :** Sugg√®re des films qu'ils ont appr√©ci√©s, mais que l'utilisateur cible n'a pas encore vus.

### 2Ô∏è‚É£ **Mod√®le Item-Item (Collaboratif bas√© sur les films)**
üîπ **Principe :** Analyse la similarit√© entre les films eux-m√™mes.  
üîπ **Recommandation :** Propose des titres similaires aux films que l'utilisateur a d√©j√† appr√©ci√©s.

## üîπ Mod√®le User-User : Cr√©ation

Le mod√®le **User-User KNN** repose sur l'id√©e que **des utilisateurs ayant des pr√©f√©rences similaires ont tendance √† aimer les m√™mes films**.  
Gr√¢ce √† l‚Äôalgorithme **KNN (K-Nearest Neighbors)**, nous identifions les **10 utilisateurs les plus proches** et nous g√©n√©rons des recommandations bas√©es sur leurs pr√©f√©rences.

---

####  Code : `modele_user_user.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import joblib

# Chargement et pr√©paration des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
user_item_matrix = data.pivot_table(index='user_id', columns='movie_title', values='rating', fill_value=0)

# Entra√Ænement du mod√®le KNN User-User
model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn.fit(user_item_matrix.values)

# Sauvegarde du mod√®le entra√Æn√©
model_path = r'C:\projet_work\Data-source\user_user_knn_model.pkl'
pd.to_pickle(model_knn, model_path)

# Fonction de recommandation 
def recommander_films(user_id, matrice, model_knn, n_reco=5):
    user_index = matrice.index.get_loc(user_id)
    distances, indices = model_knn.kneighbors([matrice.iloc[user_index].values], n_neighbors=10)
    voisins = matrice.iloc[indices[0]]
    moyenne_voisins = voisins.mean(axis=0)
    
    deja_notes = matrice.iloc[user_index] > 0
    recommandations = moyenne_voisins[~deja_notes].sort_values(ascending=False).head(n_reco)
    return recommandations

# Exemple pour utilisateur ID=1
user_id = 1
recommandations = recommander_films(user_id, user_item_matrix, model_knn, n_reco=5)

print("\nMod√®le User-User KNN cr√©√© avec succ√®s")
print(f"Recommandations finales pour l'utilisateur {user_id} :")
print(recommandations)

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python modele_user_user.py
Mod√®le User-User KNN cr√©√© avec succ√®s
Recommandations finales pour l'utilisateur 1 :
movie_title
Schindler's List (1993)                                                        3.6
Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)    3.4
E.T. the Extra-Terrestrial (1982)                                              3.3
Dave (1993)                                                                    3.3
Stand by Me (1986)                                                             3.3
dtype: float64

Bref commentaire :
Le mod√®le User-User KNN a √©t√© cr√©√© avec succ√®s et a fourni un exemple concret de recommandations pour l'utilisateur 1, illustrant son fonctionnement et sa capacit√© √† identifier des pr√©f√©rences bas√©es sur les utilisateurs similaires.
## üîπ Mod√®le User-User : √âvaluation

Apr√®s l'entra√Ænement du mod√®le **User-User KNN**, il est essentiel d‚Äô√©valuer sa pr√©cision en mesurant **l‚Äôerreur de pr√©diction** sur un ensemble de test.

üìå **M√©trique utilis√©e :**  
‚û°Ô∏è **RMSE (Root Mean Squared Error)** : Cette m√©trique mesure **l‚Äô√©cart moyen** entre les notes pr√©dites et les notes r√©elles.  
Plus la **valeur du RMSE est faible**, plus le mod√®le est pr√©cis.

---

####  Code : `evaluation_modele_user_user.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Cr√©ation matrice user-item
user_item_matrix = data.pivot_table(index='user_id', columns='movie_title', values='rating', fill_value=0)

# Split en train/test
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Matrices train/test
train_matrix = train_data.pivot_table(index='user_id', columns='movie_title', values='rating', fill_value=0)
test_matrix = test_data.pivot_table(index='user_id', columns='movie_title', values='rating', fill_value=0)

# Mod√®le KNN entra√Æn√©
model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn.fit(train_matrix.values)

# Fonction pr√©diction 
def predire_notes(user_id, film, train_matrix, model_knn):
    if user_id not in train_matrix.index or film not in train_matrix.columns:
        return np.nan
    user_index = train_matrix.index.get_loc(user_id)
    distances, indices = model_knn.kneighbors([train_matrix.iloc[user_index].values], n_neighbors=10)
    voisins = train_matrix.iloc[indices[0]]
    prediction = voisins[film][voisins[film] > 0].mean()
    return prediction if not np.isnan(prediction) else np.nan

# √âvaluation RMSE 
predictions = []
truths = []

for user_id, film in test_data[['user_id', 'movie_title']].itertuples(index=False):
    true_rating = test_matrix.loc[user_id, film]
    pred_rating = predire_notes(user_id, film, train_matrix, model_knn)
    
    if not np.isnan(pred_rating):
        predictions.append(pred_rating)
        truths.append(true_rating)

# Calcul final du RMSE
mse = mean_squared_error(truths, predictions)
rmse = np.sqrt(mse)

print(f"\n RMSE du mod√®le User-User KNN : {rmse:.3f}")

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python evaluation_modele_user_user.py
RMSE du mod√®le User-User KNN : 1.112
## üîπ Mod√®le Item-Item : Cr√©ation

Le mod√®le **Item-Item KNN** repose sur l'id√©e que **des films similaires sont souvent appr√©ci√©s par les m√™mes utilisateurs**.  
En utilisant l‚Äôalgorithme **KNN (K-Nearest Neighbors)**, nous trouvons les films **les plus proches** d‚Äôun film donn√©, afin de g√©n√©rer des recommandations **bas√©es sur la similarit√© entre films**.

---

####  Code : `modele_item_item.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import joblib

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Matrice item-user (transpose user-item pour item-item)
item_user_matrix = data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)

# Entra√Ænement du mod√®le KNN Item-Item (cosine)
model_knn_item = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_item.fit(item_user_matrix.values)

# Sauvegarde du mod√®le Item-Item
model_path = r'C:\projet_work\Model\item_item_knn_model.pkl'
joblib.dump(model_knn_item, model_path)

# Fonction de recommandation Item-Item
def recommander_films_similaires(titre_film, matrice, model_knn, n_reco=5):
    if titre_film not in matrice.index:
        return "Film non trouv√©."

    film_index = matrice.index.get_loc(titre_film)
    distances, indices = model_knn.kneighbors([matrice.iloc[film_index].values], n_neighbors=n_reco + 1)

    recommandations = matrice.index[indices.flatten()[1:]]  # exclure le film recherch√©
    return recommandations

# Exemple d'utilisation pour le film "Star Wars (1977)"
titre_film = "Star Wars (1977)"
recommandations = recommander_films_similaires(titre_film, item_user_matrix, model_knn_item, n_reco=5)

print("\nMod√®le Item-Item KNN cr√©√© avec succ√®s")
print(f"\nüé¨ Films similaires recommand√©s pour '{titre_film}':")
print(recommandations)

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python modele_item_item.py
Mod√®le Item-Item KNN cr√©√© avec succ√®s

Films similaires recommand√©s pour 'Star Wars (1977)':
Index(['Return of the Jedi (1983)', 'Raiders of the Lost Ark (1981)',
       'Empire Strikes Back, The (1980)', 'Toy Story (1995)',
       'Godfather, The (1972)'],
      dtype='object', name='movie_title')
Bref commentaire :
Le mod√®le Item-Item KNN a √©t√© cr√©√© avec succ√®s et a fourni un exemple concret de recommandations pour "Star Wars (1977)", incluant notamment "Return of the Jedi (1983)", "Raiders of the Lost Ark (1981)", "Empire Strikes Back, The (1980)", "Toy Story (1995)" et "Godfather, The (1972)".
## üîπ Mod√®le Item-Item : √âvaluation

---

####  Code : `evaluation_modele_item_item.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Split en train/test
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Matrices item-user (train et test)
train_matrix = train_data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)
test_matrix = test_data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)

# Entra√Ænement du mod√®le
model_knn_item = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_item.fit(train_matrix.values)

# Fonction pr√©diction Item-Item
def predire_notes_item(film, user_id, train_matrix, model_knn):
    if film not in train_matrix.index or user_id not in train_matrix.columns:
        return np.nan
    
    film_index = train_matrix.index.get_loc(film)
    distances, indices = model_knn.kneighbors([train_matrix.iloc[film_index].values], n_neighbors=10)
    voisins = train_matrix.iloc[indices[0]]
    prediction = voisins[user_id][voisins[user_id] > 0].mean()
    
    return prediction if not np.isnan(prediction) else np.nan

# √âvaluation RMSE 
predictions, truths = [], []

for film, user_id in test_data[['movie_title', 'user_id']].itertuples(index=False):
    true_rating = test_matrix.loc[film, user_id]
    pred_rating = predire_notes_item(film, user_id, train_matrix, model_knn_item)

    if not np.isnan(pred_rating):
        predictions.append(pred_rating)
        truths.append(true_rating)

# Calcul RMSE
mse = mean_squared_error(truths, predictions)
rmse = np.sqrt(mse)

print(f"\n RMSE du mod√®le Item-Item KNN : {rmse:.3f}")

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python evaluation_modele_item_item.py
RMSE du mod√®le Item-Item KNN : 1.031
‚úÖ Ces r√©sultats montrent que le mod√®le Item-Item KNN est plus performant et qu'il capture mieux les relations entre films.
## üîπh. Mod√®le bas√© sur le Contenu (Genres) : Cr√©ation

Le mod√®le **Content-Based KNN** repose sur l'id√©e que **des films partageant des caract√©ristiques similaires (comme les genres) seront appr√©ci√©s par les m√™mes utilisateurs**.  
En utilisant **KNN (K-Nearest Neighbors)**, nous identifions **les films les plus proches** d‚Äôun film donn√© **en fonction de leurs genres**.

---

####  Code : `modele_content_based.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import joblib

# Chargement des donn√©es
movies = pd.read_csv(r'C:\projet_work\Data-source\clean_movie.csv')

# S√©lection des colonnes de genres uniquement
genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

movie_genres_matrix = movies.set_index('movie_title')[genres]

# Entra√Ænement du mod√®le KNN Content-Based (cosine)
model_knn_content = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_content.fit(movie_genres_matrix.values)

# Sauvegarde du mod√®le
model_path = r'C:\projet_work\Model\content_based_knn_model.pkl'
joblib.dump(model_knn_content, model_path)

# Fonction de recommandation bas√©e sur contenu (genres)
def recommander_films_par_genres(titre_film, matrice_genres, model_knn, n_reco=5):
    if titre_film not in matrice_genres.index:
        return "Film non trouv√©."

    film_index = matrice_genres.index.get_loc(titre_film)
    distances, indices = model_knn.kneighbors([matrice_genres.iloc[film_index].values], n_neighbors=n_reco + 1)
    recommandations = matrice_genres.index[indices.flatten()[1:]]
    
    return recommandations

# Exemple d'utilisation pour le film "Star Wars (1977)"
titre_film = "Star Wars (1977)"
recommandations = recommander_films_par_genres(titre_film, movie_genres_matrix, model_knn_content, n_reco=5)

print("\nMod√®le Content_based_recommandation cr√©√© avec succ√®s")
print(f"\nüé¨ Films similaires recommand√©s √† '{titre_film}' (Content-Based) :")
print(recommandations)

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python modele_content_based.py
Mod√®le Content_based_recommandation cr√©√© avec succ√®s
Films similaires recommand√©s √† 'Star Wars (1977)' (Content-Based) :
Index(['Return of the Jedi (1983)', 'Empire Strikes Back, The (1980)',
       'African Queen, The (1951)', 'Starship Troopers (1997)',
       'Star Trek V: The Final Frontier (1989)'],
      dtype='object', name='movie_title')
Bref commentaire :
Le mod√®le Content-Based KNN a √©t√© cr√©√© avec succ√®s.
Pour "Star Wars (1977)", il recommande des films partageant des caract√©ristiques de contenu similaires, tels que :

"Return of the Jedi (1983)", "Empire Strikes Back, The (1980)","African Queen, The (1951)","Starship Troopers (1997)","Star Trek V: The Final Frontier (1989)".

## üîπ Mod√®le bas√© sur le Contenu (Genres) : √âvaluation

Apr√®s l'entra√Ænement du mod√®le **Content-Based KNN**, il est essentiel d‚Äô√©valuer sa pr√©cision en mesurant **l‚Äôerreur de pr√©diction** sur un ensemble de test.

üìå **M√©trique utilis√©e :**  
‚û°Ô∏è **RMSE (Root Mean Squared Error)** : Cette m√©trique mesure **l‚Äô√©cart moyen** entre les notes pr√©dites et les notes r√©elles.  
Plus la **valeur du RMSE est faible**, plus le mod√®le est pr√©cis.

---

#### Code : `evaluation_modele_content_based.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
movies = pd.read_csv(r'C:\projet_work\Data-source\clean_movie.csv')

genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

# Suppression des doublons avant cr√©ation de la matrice genre
movies_unique = movies.drop_duplicates(subset='movie_title').set_index('movie_title')

# Matrice genre sans doublons
movie_genres_matrix = movies_unique[genres]

# Entra√Ænement du mod√®le KNN Content-Based
model_knn_content = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_content.fit(movie_genres_matrix.values)

# Split train/test
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

#  Fonction de pr√©diction
def predire_notes_content(user_id, film, train_data, genres_matrix, model_knn):
    films_notes_user = train_data[train_data['user_id'] == user_id].groupby('movie_title')['rating'].mean()

    if film not in genres_matrix.index:
        return np.nan

    film_vector = genres_matrix.loc[film].values.reshape(1, -1)
    distances, indices = model_knn.kneighbors(film_vector, n_neighbors=10)
    films_similaires = genres_matrix.index[indices.flatten()[1:]]

    notes_similaires = films_notes_user[films_notes_user.index.isin(films_similaires)]
    
    pred_rating = notes_similaires.mean() if not notes_similaires.empty else np.nan
    return pred_rating

#  √âvaluation avec RMSE
predictions, truths = [], []

for user_id, film, true_rating in test_data[['user_id', 'movie_title', 'rating']].itertuples(index=False):
    pred_rating = predire_notes_content(user_id, film, train_data, movie_genres_matrix, model_knn_content)
    if not np.isnan(pred_rating):
        predictions.append(pred_rating)
        truths.append(true_rating)

# Calcul du RMSE
rmse = np.sqrt(mean_squared_error(truths, predictions))

print(f"\n RMSE du mod√®le Content-Based KNN : {rmse:.3f}")

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python evaluation_modele_content_based.py
RMSE du mod√®le Content-Based KNN : 1.266
Compar√© aux mod√®les User-User et Item-Item KNN, ce mod√®le a un RMSE plus √©lev√©, ce qui signifie qu'il est moins pr√©cis pour pr√©dire les notes exactes.
## üîπi. Mod√®le Hybride Content-User : Cr√©ation

Le mod√®le **Hybrid Content-User KNN** combine **deux sources d‚Äôinformation** :
- üîπ **Les similarit√©s entre films (Content-Based)** : En se basant sur les **genres** pour identifier des films similaires.
- üîπ **Les similarit√©s entre utilisateurs (User-User)** : En trouvant des **utilisateurs proches ayant des go√ªts similaires**.

üìå **Objectif :** Am√©liorer la pertinence des recommandations en **fusionnant les pr√©f√©rences des utilisateurs avec la similarit√© des films**.

---

####  Code : `modele_hybrid_content_user.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import joblib

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
movies = pd.read_csv(r'C:\projet_work\Data-source\clean_movie.csv')

# D√©finition des genres
genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

# Matrice des genres (Content-Based)
movies_unique = movies.drop_duplicates(subset='movie_title').set_index('movie_title')
movie_genres_matrix = movies_unique[genres]

# Matrice utilisateur-film (User-User)
user_item_matrix = data.pivot_table(index='user_id', columns='movie_title', values='rating', fill_value=0)

# Mod√®le Content-Based
model_knn_content = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_content.fit(movie_genres_matrix.values)

# Mod√®le User-User
model_knn_user = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_user.fit(user_item_matrix.values)

# Sauvegarde des mod√®les
joblib.dump(model_knn_content, r'C:\projet_work\Model\hybrid_content_knn.pkl')
joblib.dump(model_knn_user, r'C:\projet_work\Model\hybrid_user_knn.pkl')

# Fonction de recommandation hybride
def recommander_films_hybride(user_id, film, user_matrix, genre_matrix, model_knn_user, model_knn_content, n_reco=5):
    if film not in genre_matrix.index or user_id not in user_matrix.index:
        return "Utilisateur ou film non trouv√©."

    # Phase 1 : Recommandation Content-Based (Films similaires)
    film_vector = genre_matrix.loc[film].values.reshape(1, -1)
    _, indices_film = model_knn_content.kneighbors(film_vector, n_neighbors=10)
    films_similaires = genre_matrix.index[indices_film.flatten()[1:]]

    # Phase 2 : Recommandation User-User (Utilisateurs similaires)
    user_vector = user_matrix.loc[user_id].values.reshape(1, -1)
    _, indices_user = model_knn_user.kneighbors(user_vector, n_neighbors=10)
    users_similaires = user_matrix.index[indices_user.flatten()[1:]]

    # Fusion des recommandations : Films similaires not√©s par utilisateurs similaires
    films_recommandes = user_matrix.loc[users_similaires][films_similaires].mean().sort_values(ascending=False).head(n_reco)

    return films_recommandes

#  Exemple de recommandation hybride
user_id = 1
titre_film = "Star Wars (1977)"
recommandations = recommander_films_hybride(user_id, titre_film, user_item_matrix, movie_genres_matrix, model_knn_user, model_knn_content)
print("\nMod√®le Hybrid-Content-user recommandation cr√©√© avec succ√®s")
print(f"\n Films recommand√©s √† l'utilisateur {user_id} en hybride avec '{titre_film}':")
print(recommandations)

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python modele_hybrid_content_user.py
Mod√®le Hybrid-Content-user recommandation cr√©√© avec succ√®s

 Films recommand√©s √† l'utilisateur 1 en hybride avec 'Star Wars (1977)':
movie_title
Empire Strikes Back, The (1980)    4.777778
Return of the Jedi (1983)          4.333333
Jurassic Park (1993)               3.666667
Star Trek: Generations (1994)      2.222222
Stargate (1994)                    2.111111
dtype: float64

Bref commentaire :
Le mod√®le Hybrid-Content-User KNN a √©t√© cr√©√© avec succ√®s, fournissant pour l'utilisateur 1 des recommandations bas√©es sur une combinaison des similarit√©s de contenu et des pr√©f√©rences utilisateurs.
Les r√©sultats, incluant des titres comme "Empire Strikes Back, The (1980)" et "Return of the Jedi (1983)", d√©montrent la capacit√© du mod√®le √† fusionner efficacement ces deux approches.

## üîπ Mod√®le Hybride Content-User : √âvaluation

Apr√®s l'entra√Ænement du mod√®le **Hybrid Content-User KNN**, il est essentiel d‚Äô√©valuer sa pr√©cision en mesurant **l‚Äôerreur de pr√©diction** sur un ensemble de test.

üìå **M√©trique utilis√©e :**  
‚û°Ô∏è **RMSE (Root Mean Squared Error)** : Cette m√©trique mesure **l‚Äô√©cart moyen** entre les notes pr√©dites et les notes r√©elles.  
Plus la **valeur du RMSE est faible**, plus le mod√®le est pr√©cis.

---

####  Code : `evaluation_modele_hybrid_content_user.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import joblib

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
movies = pd.read_csv(r'C:\projet_work\Data-source\clean_movie.csv')

genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

# Matrice des genres (Content-Based)
movies_unique = movies.drop_duplicates(subset='movie_title').set_index('movie_title')
movie_genres_matrix = movies_unique[genres]

# Matrice utilisateur-film (User-User)
user_item_matrix = data.pivot_table(index='user_id', columns='movie_title', values='rating', fill_value=0)

# Chargement des mod√®les sauvegard√©s
model_knn_content = joblib.load(r'C:\projet_work\Model\hybrid_content_knn.pkl')
model_knn_user = joblib.load(r'C:\projet_work\Model\hybrid_user_knn.pkl')

# Fonction d‚Äô√©valuation
def predire_notes_hybride(user_id, film, user_matrix, genre_matrix, model_knn_user, model_knn_content):
    if film not in genre_matrix.index or user_id not in user_matrix.index:
        return np.nan

    # Phase 1 : Films similaires (Content-Based)
    film_vector = genre_matrix.loc[film].values.reshape(1, -1)
    _, indices_film = model_knn_content.kneighbors(film_vector, n_neighbors=10)
    films_similaires = genre_matrix.index[indices_film.flatten()[1:]]

    # Phase 2 : Utilisateurs similaires (User-User)
    user_vector = user_matrix.loc[user_id].values.reshape(1, -1)
    _, indices_user = model_knn_user.kneighbors(user_vector, n_neighbors=10)
    users_similaires = user_matrix.index[indices_user.flatten()[1:]]

    # Fusion : Notes des utilisateurs similaires sur films similaires
    notes_similaires = user_matrix.loc[users_similaires, films_similaires].mean()
    prediction = notes_similaires.mean() if not notes_similaires.empty else np.nan

    return prediction

# √âvaluation RMSE
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

predictions, truths = [], []

for user_id, film, true_rating in test_data[['user_id', 'movie_title', 'rating']].itertuples(index=False):
    pred_rating = predire_notes_hybride(user_id, film, user_item_matrix, movie_genres_matrix, model_knn_user, model_knn_content)
    
    if not np.isnan(pred_rating):
        predictions.append(pred_rating)
        truths.append(true_rating)

# Calcul du RMSE
rmse = np.sqrt(mean_squared_error(truths, predictions))
print(f"\n RMSE du mod√®le Hybrid Content-User KNN : {rmse:.3f}")

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python evaluation_modele_hybrid_content_user.py
RMSE du mod√®le Hybrid Content-User KNN : 3.115
l‚Äô√©cart moyen entre les notes pr√©dites par le mod√®le et les notes r√©elles est assez √©lev√©, ce qui sugg√®re que ce mod√®le hybride n'est pas aussi pr√©cis que les autres mod√®les test√©s.
## üîπ Mod√®le Hybride Content-Item : Cr√©ation

Le mod√®le **Hybrid Content-Item KNN** combine **deux types de similarit√©s** :
- üîπ **Les similarit√©s de contenu (Content-Based)** : En comparant les **genres** des films.
- üîπ **Les similarit√©s de notation des utilisateurs (Item-Item Collaborative Filtering)** : En identifiant **les films not√©s de mani√®re similaire**.

üìå **Objectif :** Am√©liorer la pr√©cision des recommandations en combinant **deux sources d'information** pour identifier des films pertinents.

---

####  Code : `modele_hybrid_content_item.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import joblib

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
movies = pd.read_csv(r'C:\projet_work\Data-source\clean_movie.csv')

# D√©finition des genres
genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

# Matrice des genres (Content-Based)
movies_unique = movies.drop_duplicates(subset='movie_title').set_index('movie_title')
movie_genres_matrix = movies_unique[genres]

# Matrice film-utilisateur (Item-Item)
item_user_matrix = data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)

# V√©rifier si `Star Wars (1977)` est bien dans les matrices
print(f"'Star Wars (1977)' dans Content-Based : {'Star Wars (1977)' in movie_genres_matrix.index}")
print(f"'Star Wars (1977)' dans Item-Item : {'Star Wars (1977)' in item_user_matrix.index}")

# Mod√®le Content-Based
model_knn_content = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_content.fit(movie_genres_matrix.values)

# Mod√®le Item-Item
model_knn_item = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
model_knn_item.fit(item_user_matrix.values)

# Sauvegarde des mod√®les
joblib.dump(model_knn_content, r'C:\projet_work\Model\hybrid_content_knn.pkl')
joblib.dump(model_knn_item, r'C:\projet_work\Model\hybrid_item_knn.pkl')

# Fonction de recommandation hybride (Content + Item)
def recommander_films_hybride_item(film, item_matrix, genre_matrix, model_knn_item, model_knn_content, n_reco=5):
    if film not in genre_matrix.index or film not in item_matrix.index:
        return "Film non trouv√©."

    # Phase 1 : Recommandation Content-Based (Films similaires en genre)
    film_vector = genre_matrix.loc[film].values.reshape(1, -1)
    _, indices_film_content = model_knn_content.kneighbors(film_vector, n_neighbors=10)
    films_similaires_content = genre_matrix.index[indices_film_content.flatten()[1:]]

    # Phase 2 : Recommandation Item-Item (Films similaires par notes des utilisateurs)
    film_vector = item_matrix.loc[film].values.reshape(1, -1)
    _, indices_film_item = model_knn_item.kneighbors(film_vector, n_neighbors=10)
    films_similaires_item = item_matrix.index[indices_film_item.flatten()[1:]]

    # Fusion am√©lior√©e des recommandations
    films_similaires_content = set(films_similaires_content)
    films_similaires_item = set(films_similaires_item)

    films_recommandes = list(films_similaires_content.union(films_similaires_item))[:n_reco]

    return films_recommandes if films_recommandes else ["Aucune recommandation trouv√©e."]

# Exemple de recommandation hybride
titre_film = "Star Wars (1977)"
recommandations = recommander_films_hybride_item(titre_film, item_user_matrix, movie_genres_matrix, model_knn_item, model_knn_content)

print("\nMod√®le Hybrid-Content-Item recommandation cr√©√© avec succ√®s")
print(f"\n Films recommand√©s avec le mod√®le hybride Content-Item pour '{titre_film}':")
print(recommandations)

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python modele_hybrid_content_item.py
'Star Wars (1977)' dans Content-Based : True
'Star Wars (1977)' dans Item-Item : True

Mod√®le Hybrid-Content-Item recommandation cr√©√© avec succ√®s

 Films recommand√©s avec le mod√®le hybride Content-Item pour 'Star Wars (1977)':
['Raiders of the Lost Ark (1981)', 'Empire Strikes Back, The (1980)', 'Starship Troopers (1997)', 'Stargate (1994)', 'Independence Day (ID4) (1996)']

Bref commentaire :
Le mod√®le Hybrid-Content-Item KNN a √©t√© cr√©√© avec succ√®s, combinant la similarit√© bas√©e sur le contenu et celle fond√©e sur les notations collaboratives.
Pour "Star Wars (1977)", les recommandations obtenues, telles que "Raiders of the Lost Ark (1981)" et "Empire Strikes Back, The (1980)", d√©montrent la capacit√© du mod√®le √† identifier des films aux caract√©ristiques et √† l'audience similaires.

## üîπ Mod√®le Hybride Content-Item : √âvaluation

Apr√®s l'entra√Ænement du mod√®le **Hybrid Content-Item KNN**, il est essentiel d‚Äô√©valuer sa pr√©cision en mesurant **l‚Äôerreur de pr√©diction** sur un ensemble de test.

üìå **M√©trique utilis√©e :**  
‚û°Ô∏è **RMSE (Root Mean Squared Error)** : Cette m√©trique mesure **l‚Äô√©cart moyen** entre les notes pr√©dites et les notes r√©elles.  
Plus la **valeur du RMSE est faible**, plus le mod√®le est pr√©cis.

---

#### Code : `evaluation_modele_hybrid_content_item.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import joblib

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
movies = pd.read_csv(r'C:\projet_work\Data-source\clean_movie.csv')

genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

# Matrice des genres (Content-Based)
movies_unique = movies.drop_duplicates(subset='movie_title').set_index('movie_title')
movie_genres_matrix = movies_unique[genres]

# Matrice film-utilisateur (Item-Item)
item_user_matrix = data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)

# Chargement des mod√®les sauvegard√©s
model_knn_content = joblib.load(r'C:\projet_work\Model\hybrid_content_knn.pkl')
model_knn_item = joblib.load(r'C:\projet_work\Model\hybrid_item_knn.pkl')

# Fonction d‚Äô√©valuation
def predire_notes_hybride_item(film, user_id, item_matrix, genre_matrix, model_knn_item, model_knn_content):
    if film not in genre_matrix.index or film not in item_matrix.index or user_id not in item_matrix.columns:
        return np.nan

    # Phase 1 : Films similaires (Content-Based)
    film_vector = genre_matrix.loc[film].values.reshape(1, -1)
    _, indices_film_content = model_knn_content.kneighbors(film_vector, n_neighbors=10)
    films_similaires_content = genre_matrix.index[indices_film_content.flatten()[1:]]

    # Phase 2 : Films similaires (Item-Item)
    film_vector = item_matrix.loc[film].values.reshape(1, -1)
    _, indices_film_item = model_knn_item.kneighbors(film_vector, n_neighbors=10)
    films_similaires_item = item_matrix.index[indices_film_item.flatten()[1:]]

    # Fusion : Notes des films similaires sur Item-Item et Content-Based
    films_similaires = list(set(films_similaires_content).union(set(films_similaires_item)))
    notes_similaires = item_matrix.loc[films_similaires, user_id].dropna()
    
    prediction = notes_similaires.mean() if not notes_similaires.empty else np.nan
    return prediction

# √âvaluation RMSE
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

predictions, truths = [], []

for film, user_id, true_rating in test_data[['movie_title', 'user_id', 'rating']].itertuples(index=False):
    pred_rating = predire_notes_hybride_item(film, user_id, item_user_matrix, movie_genres_matrix, model_knn_item, model_knn_content)
    
    if not np.isnan(pred_rating):
        predictions.append(pred_rating)
        truths.append(true_rating)

# Calcul du RMSE
rmse = np.sqrt(mean_squared_error(truths, predictions))
print(f"\n RMSE du mod√®le Hybrid Content-Item KNN : {rmse:.3f}")

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python evaluation_modele_hybrid_content_item.py
 RMSE du mod√®le Hybrid Content-Item KNN : 2.370

 Resum√©
Mod√®le	RMSE
User-User KNN	1.112
Item-Item KNN	1.031
Content-Based KNN	1.266
Hybrid Content-User KNN	3.115
Hybrid Content-Item KNN	2.370

## Analyse des r√©sultats

Les mod√®les de recommandation bas√©s sur KNN offrent des r√©sultats int√©ressants avec des nuances distinctes :

- **Item-Item KNN** est le plus performant.
- **Hybrid Content-Item KNN** est un bon √©quilibre entre contenu et notes utilisateurs.
- **Content-Based KNN** seul est limit√©, car il ne tient pas compte des pr√©f√©rences des utilisateurs.

Maintenant que nous avons test√© diff√©rents mod√®les KNN (**User-User, Item-Item, Content-Based, Hybrides**) et √©valu√© leurs performances avec RMSE, nous allons proc√©der √† **l‚Äôoptimisation des hyperparam√®tres** pour am√©liorer encore plus la pr√©cision.

## üîπ Optimisation des hyperparam√®tres pour am√©liorer les performances

Nous allons **ajuster automatiquement les hyperparam√®tres** pour trouver les **meilleures valeurs** :

1. **n_neighbors** ‚Üí Le nombre de voisins pris en compte dans la recommandation (**2, 5, 10**).
2. **metric** ‚Üí La mesure de distance utilis√©e (**cosine, euclidean, manhattan**).
3. **algorithm** ‚Üí Algorithmes influen√ßant la vitesse d'ex√©cution (**brute, ball_tree, kd_tree**).

**Mod√®les optimis√©s :**
- **Item-Item KNN** (meilleur RMSE initial : **1.031**)
- **Hybrid Content-Item KNN** (meilleur mod√®le hybride : **RMSE 2.370**)

---

### üîπ Mod√®le Item-Item KNN : Optimisation

####  Code : `optimisation_item_item.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Chargement des donn√©es
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Cr√©ation de la matrice film-utilisateur (Item-Item)
item_user_matrix = data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)

# Remplacer les NaN par la moyenne du film
item_user_matrix = item_user_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)

# D√©finition de la grille d'hyperparam√®tres
param_grid = {
    'n_neighbors': [2, 5, 10],
    'metric': ['cosine', 'euclidean', 'manhattan'],
    'algorithm': ['auto', 'ball_tree', 'brute']
}

# Initialisation des meilleurs param√®tres
best_params = None
best_rmse = float('inf')

# S√©paration des donn√©es en train/test
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)
train_matrix = train_data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)
test_matrix = test_data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)

# V√©rification des films en commun entre train et test
films_test = set(test_matrix.index)
films_train = set(train_matrix.index)
films_communs = films_test.intersection(films_train)

# Limiter les tests √† un sous-ensemble de 200 films pour acc√©l√©rer le traitement
test_matrix_sample = test_matrix.sample(n=200, random_state=42)

# Boucle de validation crois√©e sur les hyperparam√®tres
for n_neighbors in param_grid['n_neighbors']:
    for metric in param_grid['metric']:
        for algorithm in param_grid['algorithm']:
            if metric == 'cosine' and algorithm != 'brute':
                continue

            knn = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, algorithm=algorithm)
            
            # Entra√Ænement sur la matrice train
            knn.fit(train_matrix.values)

            predictions = []
            truths = []

            for movie, user in test_matrix_sample.stack().index:
                if movie in train_matrix.index and user in train_matrix.columns:
                    try:
                        distances, indices = knn.kneighbors(
                            [train_matrix.loc[movie].values],
                            n_neighbors=min(n_neighbors, len(train_matrix))
                        )
                        films_similaires = train_matrix.index[indices.flatten()[1:]]
                        notes_moyennes = train_matrix.loc[films_similaires, user].mean()

                        if not np.isnan(notes_moyennes):
                            predictions.append(notes_moyennes)
                            truths.append(test_matrix.loc[movie, user])
                    except Exception as e:
                        continue

            if predictions and truths and len(predictions) == len(truths):
                current_rmse = np.sqrt(mean_squared_error(truths, predictions))
                if current_rmse < best_rmse:
                    best_rmse = current_rmse
                    best_params = {'n_neighbors': n_neighbors, 'metric': metric, 'algorithm': algorithm}

# Affichage des meilleurs hyperparam√®tres
if best_params:
    print(f"\n Meilleurs hyperparam√®tres trouv√©s pour Item-Item KNN : {best_params}")
    print(f" RMSE optimis√© : {best_rmse:.3f}")
else:
    print("\n‚ùå Aucune combinaison d'hyperparam√®tres n'a donn√© un RMSE valide.")

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python optimisation_item_item.py
 V√©rification des donn√©es avant optimisation...

 Taille train_matrix : (1446, 933), test_matrix : (1308, 933)
 Nombre total de films dans test_matrix : 1308
 Nombre total de films dans train_matrix : 1446
 Films en commun entre train et test : 1305
 Films s√©lectionn√©s pour l'optimisation : 200

 Test de : n_neighbors=10, metric=manhattan, algorithm=ball_tree
RMSE pour cette configuration : 0.496

 Meilleurs hyperparam√®tres trouv√©s pour Item-Item KNN :
 {'n_neighbors': 10, 'metric': 'manhattan', 'algorithm': 'ball_tree'}
 RMSE optimis√© : 0.496

## üîπ Optimisation des hyperparam√®tres pour le mod√®le Hybrid Content-Item KNN

Nous allons **ajuster automatiquement les hyperparam√®tres** pour trouver les **meilleures valeurs** et am√©liorer les performances du mod√®le **Hybrid Content-Item KNN**.

üìå **Hyperparam√®tres optimis√©s :**
1. **n_neighbors** ‚Üí Le nombre de voisins pris en compte dans la recommandation (**2, 5, 10**).
2. **metric** ‚Üí La mesure de distance utilis√©e (**cosine, euclidean, manhattan**).
3. **algorithm** ‚Üí Algorithmes influen√ßant la vitesse d'ex√©cution (**brute, ball_tree, kd_tree**).

üìå **Mod√®le optimis√© :**
- **Hybrid Content-Item KNN** (**RMSE initial : 2.370**)

---

### üîπ Mod√®le Hybrid Content-Item KNN : Optimisation

#### üíª Code : `optimisation_hybrid_content_item.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# ------------------ Chargement des donn√©es ------------------
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')
movies = pd.read_csv(r'C:\projet_work\Data-source\clean_movie.csv')

# Liste des genres
genres = ['Action','Adventure','Animation',"Children's",'Comedy','Crime',
          'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical',
          'Mystery','Romance','Sci-Fi','Thriller','War','Western']

# ------------------ Construction des matrices ------------------
movies_unique = movies.drop_duplicates(subset='movie_title').set_index('movie_title')
genre_matrix = movies_unique[genres]

item_user_matrix = data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)
item_user_matrix = item_user_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)

# ------------------ S√©paration Train/Test ------------------
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)
train_item_matrix = train_data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)
test_item_matrix = test_data.pivot_table(index='movie_title', columns='user_id', values='rating', fill_value=0)
train_item_matrix = train_item_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)
test_item_matrix = test_item_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)

# ------------------ D√©finition des grilles d'hyperparam√®tres ------------------
param_grid_content = {'n_neighbors': [2, 5, 10], 'metric': ['cosine'], 'algorithm': ['brute']}
param_grid_item = {'n_neighbors': [2, 5, 10], 'metric': ['euclidean', 'manhattan'], 'algorithm': ['auto', 'ball_tree', 'brute']}

# ------------------ Fonction de pr√©diction hybride ------------------
def predict_hybrid_rating(film, user, item_matrix, genre_matrix, knn_item, knn_content):
    if film not in genre_matrix.index or film not in item_matrix.index or user not in item_matrix.columns:
        return np.nan

    film_vector_content = genre_matrix.loc[film].values.reshape(1, -1)
    _, indices_content = knn_content.kneighbors(film_vector_content, n_neighbors=10)
    similar_films_content = genre_matrix.index[indices_content.flatten()[1:]]
    
    film_vector_item = item_matrix.loc[film].values.reshape(1, -1)
    _, indices_item = knn_item.kneighbors(film_vector_item, n_neighbors=10)
    similar_films_item = item_matrix.index[indices_item.flatten()[1:]]
    
    similar_films = list(set(similar_films_content).union(set(similar_films_item)))
    if len(similar_films) == 0:
        return np.nan

    ratings_similar = item_matrix.loc[similar_films, user]
    return ratings_similar.mean() if not ratings_similar.empty else np.nan

# ------------------ Optimisation des hyperparam√®tres ------------------
best_params = None
best_rmse = float('inf')

test_sample = test_data.sample(n=200, random_state=42)

for n_neighbors_content in param_grid_content['n_neighbors']:
    for metric_content in param_grid_content['metric']:
        for algorithm_content in param_grid_content['algorithm']:
            knn_content = NearestNeighbors(n_neighbors=n_neighbors_content, metric=metric_content, algorithm=algorithm_content)
            knn_content.fit(genre_matrix.values)
            
            for n_neighbors_item in param_grid_item['n_neighbors']:
                for metric_item in param_grid_item['metric']:
                    for algorithm_item in param_grid_item['algorithm']:
                        knn_item = NearestNeighbors(n_neighbors=n_neighbors_item, metric=metric_item, algorithm=algorithm_item)
                        knn_item.fit(train_item_matrix.values)
                        
                        predictions, truths = [], []

                        for user, film, true_rating in test_sample[['user_id', 'movie_title', 'rating']].itertuples(index=False):
                            pred = predict_hybrid_rating(film, user, train_item_matrix, genre_matrix, knn_item, knn_content)
                            if not np.isnan(pred):
                                predictions.append(pred)
                                truths.append(true_rating)

                        if predictions and truths and len(predictions) == len(truths):
                            rmse = np.sqrt(mean_squared_error(truths, predictions))
                            if rmse < best_rmse:
                                best_rmse = rmse
                                best_params = {
                                    'content': {'n_neighbors': n_neighbors_content, 'metric': metric_content, 'algorithm': algorithm_content},
                                    'item': {'n_neighbors': n_neighbors_item, 'metric': metric_item, 'algorithm': algorithm_item}
                                }

# ------------------ Affichage final ------------------
if best_params:
    print(f"\n‚úÖ Meilleurs hyperparam√®tres pour Hybrid Content-Item KNN : {best_params}")
    print(f" RMSE optimis√© : {best_rmse:.3f}")
else:
    print("\n‚ùå Aucune combinaison d'hyperparam√®tres n'a donn√© un RMSE valide.")

---

#### ‚ñ∂Ô∏è R√©sultats de l‚Äôex√©cution

```bash
PS C:\projet_work\Script> python optimisation_hybrid_content_item.py
‚úÖ Meilleurs hyperparam√®tres pour Hybrid Content-Item KNN :
{'content': {'n_neighbors': 2, 'metric': 'cosine', 'algorithm': 'brute'},
 'item': {'n_neighbors': 2, 'metric': 'euclidean', 'algorithm': 'ball_tree'}}
 RMSE optimis√© : 3.222
##  Bref commentaire et choix du mod√®le d√©finitif

Apr√®s avoir test√© et optimis√© plusieurs mod√®les de recommandation bas√©s sur **KNN**, nous avons observ√© des performances vari√©es selon les approches :

- **Item-Item KNN** offre la **meilleure pr√©cision** avec un **RMSE optimis√© √† 0.496**, surpassant tous les autres mod√®les.
- **User-User KNN** et **Content-Based KNN** pr√©sentent des limites, respectivement li√©es √† la sparsit√© des donn√©es et √† l'absence de prise en compte des pr√©f√©rences utilisateurs.
- **Les mod√®les hybrides (Content-User et Content-Item)**, bien que prometteurs, n‚Äôont pas atteint une pr√©cision suffisante pour surpasser **Item-Item KNN**.

 **Mod√®le d√©finitif retenu :**
‚úÖ **Le mod√®le Item-Item KNN** est **le plus robuste et pr√©cis** pour notre **syst√®me de recommandation**.  
Bien que le mod√®le hybride int√®gre des **informations suppl√©mentaires** (**genres + notations**), **la mani√®re de les combiner n√©cessite encore une optimisation**.

 **Ce mod√®le sera donc utilis√© comme solution finale pour g√©n√©rer des recommandations de films pr√©cises et efficaces.**
# üîπ VI. Produit Final Fonctionnel et D√©ploiement

Pour rendre le syst√®me de recommandation **facilement accessible**, j'ai d√©velopp√© :
-  **Un script interactif en Python**, permettant √† un utilisateur d‚Äôentrer son `userId` et de recevoir des recommandations personnalis√©es.
- **Une API RESTful** (d√©crite plus tard), permettant aux d√©veloppeurs **d‚Äôint√©grer ces recommandations** dans leurs applications.
- **Un guide d'utilisation** d√©taillant **comment ex√©cuter le script** ou **interagir avec l‚ÄôAPI**.

L‚Äôobjectif est de fournir **une interface intuitive et efficace** pour que **tout utilisateur** puisse facilement **obtenir des recommandations personnalis√©es**.

---

## üìå 1Ô∏è‚É£ Script Python interactif - Recommandations en temps r√©el

L'utilisateur **saisit son `userId`** et le syst√®me **renvoie ses recommandations de films**, en utilisant le **mod√®le Item-Item KNN** optimis√©.

---

### Code : `recommandations_interactives.py`

```python
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors

# Chargement des donn√©es et cr√©ation de la matrice utilisateur-film
data = pd.read_csv(r'C:\projet_work\Data-source\merged_final_data.csv')

# Cr√©ation de la matrice : lignes = user_id, colonnes = movie_title, valeurs = rating (0 si non not√©)
user_item_matrix = data.pivot_table(index='user_id', columns='movie_title', values='rating', fill_value=0)

# Construction du mod√®le Item-Item KNN avec les meilleurs hyperparam√®tres
knn = NearestNeighbors(n_neighbors=10, metric='manhattan', algorithm='ball_tree')
knn.fit(user_item_matrix.T.values)

def predict_rating(user_id, movie, user_item_matrix, knn, k=10):
    """
    Pr√©dit la note de 'movie' pour 'user_id' en utilisant une approche Item-Item.
    Si l'utilisateur a d√©j√† not√© le film, retourne la note r√©elle.
    Sinon, calcule la moyenne des notes de ce m√™me utilisateur pour des films similaires.
    """
    if user_item_matrix.loc[user_id, movie] != 0:
        return user_item_matrix.loc[user_id, movie]

    movie_vector = user_item_matrix.T.loc[movie].values.reshape(1, -1)
    distances, indices = knn.kneighbors(movie_vector, n_neighbors=k)

    similar_movies = user_item_matrix.T.index[indices.flatten()]
    similar_movies = [m for m in similar_movies if m != movie]

    ratings = [user_item_matrix.loc[user_id, m] for m in similar_movies if user_item_matrix.loc[user_id, m] != 0]

    return np.mean(ratings) if ratings else 0

def get_recommendations(user_id, user_item_matrix, knn, top_n=5):
    """
    Pour un utilisateur donn√©, pr√©dit les notes des films non not√©s et retourne les top_n recommandations.
    """
    unrated_movies = user_item_matrix.columns[user_item_matrix.loc[user_id] == 0]
    predictions = {movie: predict_rating(user_id, movie, user_item_matrix, knn) for movie in unrated_movies}

    sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)
    return sorted_predictions[:top_n]

# --- Script interactif ---
user_input = input("Entrez votre userId: ")
try:
    user_id = int(user_input)
except ValueError:
    print("UserId invalide. Veuillez entrer un entier.")
    exit()

if user_id not in user_item_matrix.index:
    print("UserId non trouv√© dans la base de donn√©es.")
    exit()

recommendations = get_recommendations(user_id, user_item_matrix, knn, top_n=5)

print(f"\nüé¨ Recommandations pour l'utilisateur {user_id}:")
for movie, score in recommendations:
    print(f"{movie}: note pr√©dite {score:.2f}")


---

### ‚ñ∂Ô∏è **Exemple d‚Äôex√©cution du script**

```bash
PS C:\projet_work\Script> python recommandations_interactives.py
Entrez votre userId: 25

üé¨ Recommandations pour l'utilisateur 25:
Groundhog Day (1993): note pr√©dite 5.00
Mr. Holland's Opus (1995): note pr√©dite 5.00
Pulp Fiction (1994): note pr√©dite 4.60
12 Angry Men (1957): note pr√©dite 4.50
Fargo (1996): note pr√©dite 4.50

### üìù Bref commentaire

Ce r√©sultat d√©montre le **fonctionnement interactif du syst√®me de recommandation** :

1. **L'utilisateur saisit son identifiant (`userId`)**.
2. **Le script v√©rifie la pr√©sence de l'utilisateur dans la base de donn√©es**.
3. **Si l'identifiant est valide, le syst√®me affiche une liste de films recommand√©s avec leurs notes pr√©dites**.
4. **Si l‚Äôidentifiant n‚Äôexiste pas (ex: `userId = 1350`), un message d'erreur est retourn√©**.

## üîπ 2Ô∏è‚É£ D√©ploiement via une API RESTful

Afin de permettre **une int√©gration facile** du syst√®me de recommandation dans d‚Äôautres applications, une **API RESTful** a √©t√© d√©velopp√©e en utilisant **Flask**.

üìå **Fonctionnalit√©s de l‚ÄôAPI :**
- ‚úÖ **Obtenir des recommandations** en envoyant une requ√™te HTTP avec un `userId`.
- ‚úÖ **Retourne une liste de films recommand√©s** en format **JSON**.
- ‚úÖ **Facilement int√©grable** dans d'autres applications (web, mobile, etc.).

---

### ‚ñ∂Ô∏è **Lancement de l‚ÄôAPI**
L'API peut √™tre lanc√©e via le script **`api_recommendations.py`** :

```bash
PS C:\projet_work\Script> python api_recommendations.py
 * Serving Flask app 'api_recommendations'
 * Debug mode: on
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit

http://127.0.0.1:5000/recommendations?userId=20
### üì∏ **Aper√ßu de l‚ÄôAPI en action**
Voici un **exemple visuel** de l'API fonctionnant dans un navigateur pour userId=20 :  

![API Screenshot](EDA/Api.png)

 Ces r√©sultats montrent que **l‚ÄôAPI Flask** r√©pond correctement aux requ√™tes **HTTP** et renvoie des **recommandations personnalis√©es** au format **JSON**.  

- ‚úÖ **La requ√™te avec `userId=20`** a abouti √† un **code `200`** et a retourn√© **un ensemble de films recommand√©s**, chacun accompagn√© de sa **note pr√©dite**.
- ‚úÖ **Sur le navigateur**, l‚Äôaffichage confirme la **bonne int√©gration de l‚ÄôAPI**, fournissant une **r√©ponse structur√©e et lisible** pour l‚Äôutilisateur.

# 3Ô∏è‚É£ üìñ Guide d'Utilisation du Syst√®me de Recommandation de Films

## üìå Introduction
Ce syst√®me de recommandation de films vous permet d'obtenir des **suggestions personnalis√©es** bas√©es sur vos pr√©f√©rences.  

Vous disposez de **deux outils principaux** :
- üñ• **Un script interactif (`recommandations_interactives.py`)** permettant d‚Äôobtenir des recommandations via la ligne de commande.
- üåç **Une API RESTful (`api_recommendations.py`)** permettant d'int√©grer le service dans une **application web ou mobile**.

---

## ‚öôÔ∏è Pr√©requis
Avant d'utiliser ce syst√®me, assurez-vous d‚Äôavoir **l‚Äôenvironnement et les fichiers n√©cessaires** :

‚úîÔ∏è **Environnement** : Python **3.7 ou sup√©rieur**.  
‚úîÔ∏è **D√©pendances** : Installez les packages suivants avec `pip` :  
   ```bash
   pip install flask pandas numpy scikit-learn

‚úîÔ∏è Donn√©es : Placez les fichiers movies.csv et ratings.csv (ou merged_final_data.csv) dans le dossier :

C:\projet_work\Data-source\
‚úîÔ∏è Scripts : Les scripts doivent √™tre situ√©s dans le dossier :

C:\projet_work\Script\

üñ•Ô∏è Utilisation du Script Interactif
1Ô∏è‚É£ Acc√®s au script
Ouvrez une invite de commande et naviguez vers le dossier des scripts :

cd C:\projet_work\Script
2Ô∏è‚É£ Ex√©cution du script
Lancez le script interactif avec :
python recommandations_interactives.py
3Ô∏è‚É£ Proc√©dure interactive
Le script vous demandera d‚Äôentrer votre identifiant utilisateur (userId).
Apr√®s saisie d‚Äôun userId valide, le syst√®me affichera une liste de films recommand√©s accompagn√©e de la note pr√©dite pour chacun.
üåç Utilisation de l'API Flask
1Ô∏è‚É£ Lancement de l‚ÄôAPI
Dans l‚Äôinvite de commande, naviguez vers le dossier des scripts et ex√©cutez :
cd C:\projet_work\Script
python api_recommendations.py
L'API d√©marrera sur :
http://127.0.0.1:5000
2Ô∏è‚É£ Acc√®s aux recommandations
Vous pouvez utiliser :
Un navigateur üñ•Ô∏è
Un outil comme Postman üõ†Ô∏è
Une requ√™te HTTP (curl, requests en Python, etc.)
L‚Äôendpoint √† appeler est :
http://127.0.0.1:5000/recommendations?userId=<votre_userId>
Remplacez <votre_userId> par votre identifiant num√©rique.
3Ô∏è‚É£ R√©ponse attendue (format JSON)
L‚ÄôAPI retourne une r√©ponse contenant les films recommand√©s et leurs notes pr√©dites, par exemple :
{
    "userId": 20,
    "recommendations": [
        {"movie": "Groundhog Day (1993)", "predicted_rating": 5.0},
        {"movie": "Mr. Holland's Opus (1995)", "predicted_rating": 5.0},
        {"movie": "Pulp Fiction (1994)", "predicted_rating": 4.60},
        {"movie": "12 Angry Men (1957)", "predicted_rating": 4.50},
        {"movie": "Fargo (1996)", "predicted_rating": 4.50}
    ]
}
‚ùì Support et Assistance
Pour toute question ou probl√®me rencontr√©, veuillez consulter la documentation technique ou contacter l‚Äô√©quipe de support √† l‚Äôadresse suivante :
üìß joye@support.badou

## üé¨ Conclusion

En conclusion, ce projet a d√©montr√© que la **mise en place d‚Äôun syst√®me de recommandation de films** est non seulement **faisable**, mais √©galement **efficace** lorsqu‚Äôon exploite un jeu de donn√©es **soigneusement pr√©par√© et analys√©**.  

D√®s la phase initiale :
- ‚úÖ **Collecte et centralisation des donn√©es** du dataset **MovieLens 100K**.
- ‚úÖ **Fiabilisation et normalisation rigoureuses**, garantissant une base solide pour l‚Äôanalyse.
- ‚úÖ **Analyse exploratoire**, permettant de comprendre les comportements des utilisateurs et d‚Äôidentifier les tendances globales.

### üìå Hypoth√®ses confirm√©es :
‚úîÔ∏è **Les utilisateurs ayant des notations similaires partagent des go√ªts proches.**  
‚úîÔ∏è **Les genres sont un indicateur fiable pour √©valuer la similarit√© entre films.**  
‚úîÔ∏è **Les tendances globales des notations guident efficacement les recommandations.**  

---

### üöÄ D√©veloppement et choix du mod√®le
Sur la base de ces constats, plusieurs **mod√®les de recommandation** ont √©t√© d√©velopp√©s en utilisant **KNN** :
- **User-User KNN**
- **Item-Item KNN**
- **Content-Based KNN**
- **Hybrid Content-User KNN**
- **Hybrid Content-Item KNN**

üìå **Apr√®s tests et optimisation des hyperparam√®tres** :
‚úÖ **Le mod√®le Item-Item KNN** s‚Äôest r√©v√©l√© **le plus performant**, offrant **le meilleur RMSE**.  
‚úÖ **Son approche exploite efficacement les similarit√©s entre films** pour pr√©dire les pr√©f√©rences des utilisateurs.  

---

### üñ•Ô∏è Accessibilit√© et D√©ploiement  
Le projet a √©t√© rendu **accessible en temps r√©el** gr√¢ce √† :
- üìå **Un script interactif Python** (`recommandations_interactives.py`).
- üìå **Une API RESTful Flask**, permettant **une int√©gration facile dans d‚Äôautres applications**.

---

### üîÆ Perspectives et am√©liorations futures  
Ce travail d√©montre **l‚Äôefficacit√© du filtrage collaboratif**, mais ouvre aussi la voie √† des **optimisations** :
- üîπ **Explorer des mod√®les hybrides avanc√©s** (ex: combinaisons pond√©r√©es, deep learning).
- üîπ **Int√©grer du Machine Learning supervis√©** pour affiner les recommandations.
- üîπ **Exploiter davantage les m√©tadonn√©es des films** (ex: synopsis, acteurs, r√©alisateurs).

üéØ **Ce projet offre une solution compl√®te et fonctionnelle** pour am√©liorer **l‚Äôexp√©rience utilisateur** dans la d√©couverte de films, tout en posant les bases pour des **am√©liorations futures**.

---

